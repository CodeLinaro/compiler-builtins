#![cfg(not(feature = "no-asm"))]
#![allow(unused_imports)]
#![allow(named_asm_labels)]
#[cfg(feature = "weak-intrinsics")]


use core::intrinsics;

intrinsics! {
#[naked]
    pub unsafe extern "C" fn __hexagon_divdi3() {
        core::arch::asm!(
            "{{\n",
    "  p2 = tstbit(r1,#31)\n",
    "  p3 = tstbit(r3,#31)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = abs(r1:0)\n",
    "  r3:2 = abs(r3:2)\n",
    " }}\n",
    " {{\n",
    "  r6 = cl0(r1:0)\n",
    "  r7 = cl0(r3:2)\n",
    "  r5:4 = r3:2\n",
    "  r3:2 = r1:0\n",
    " }}\n",
    " {{\n",
    "  p3 = xor(p2,p3)\n",
    "  r10 = sub(r7,r6)\n",
    "  r1:0 = #0\n",
    "  r15:14 = #1\n",
    " }}\n",
    " {{\n",
    "  r11 = add(r10,#1)\n",
    "  r13:12 = lsl(r5:4,r10)\n",
    "  r15:14 = lsl(r15:14,r10)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gtu(r5:4,r3:2)\n",
    "  loop0(1f,r11)\n",
    " }}\n",
    " {{\n",
    "  if (p0) jump .hexagon_divdi3_return\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  p0 = cmp.gtu(r13:12,r3:2)\n",
    " }}\n",
    " {{\n",
    "  r7:6 = sub(r3:2, r13:12)\n",
    "  r9:8 = add(r1:0, r15:14)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = vmux(p0, r1:0, r9:8)\n",
    "  r3:2 = vmux(p0, r3:2, r7:6)\n",
    " }}\n",
    " {{\n",
    "  r15:14 = lsr(r15:14, #1)\n",
    "  r13:12 = lsr(r13:12, #1)\n",
    " }}:endloop0\n",
    "\n",
    ".hexagon_divdi3_return:\n",
    " {{\n",
    "  r3:2 = neg(r1:0)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = vmux(p3,r3:2,r1:0)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_divsi3() {
        core::arch::asm!(
            "{{\n",
    "  p0 = cmp.ge(r0,#0)\n",
    "  p1 = cmp.ge(r1,#0)\n",
    "  r1 = abs(r0)\n",
    "  r2 = abs(r1)\n",
    " }}\n",
    " {{\n",
    "  r3 = cl0(r1)\n",
    "  r4 = cl0(r2)\n",
    "  r5 = sub(r1,r2)\n",
    "  p2 = cmp.gtu(r2,r1)\n",
    " }}\n",
    " {{\n",
    "  r0 = #0\n",
    "  p1 = xor(p0,p1)\n",
    "  p0 = cmp.gtu(r2,r5)\n",
    "  if (p2) jumpr r31\n",
    " }}\n",
    "\n",
    " {{\n",
    "  r0 = mux(p1,#-1,#1)\n",
    "  if (p0) jumpr r31\n",
    "  r4 = sub(r4,r3)\n",
    "  r3 = #1\n",
    " }}\n",
    " {{\n",
    "  r0 = #0\n",
    "  r3:2 = vlslw(r3:2,r4)\n",
    "  loop0(1f,r4)\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  p0 = cmp.gtu(r2,r1)\n",
    "  if (!p0.new) r1 = sub(r1,r2)\n",
    "  if (!p0.new) r0 = add(r0,r3)\n",
    "  r3:2 = vlsrw(r3:2,#1)\n",
    " }}:endloop0\n",
    " {{\n",
    "  p0 = cmp.gtu(r2,r1)\n",
    "  if (!p0.new) r0 = add(r0,r3)\n",
    "  if (!p1) jumpr r31\n",
    " }}\n",
    " {{\n",
    "  r0 = neg(r0)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_memcpy_likely_aligned_min32bytes_mult8bytes() {
        core::arch::asm!(
            "{{\n",
    "  p0 = bitsclr(r1,#7)\n",
    "  p0 = bitsclr(r0,#7)\n",
    "  if (p0.new) r5:4 = memd(r1)\n",
    "  r3 = #-3\n",
    " }}\n",
    " {{\n",
    "  if (!p0) jump .Lmemcpy_call\n",
    "  if (p0) memd(r0++#8) = r5:4\n",
    "  if (p0) r5:4 = memd(r1+#8)\n",
    "  r3 += lsr(r2,#3)\n",
    " }}\n",
    " {{\n",
    "  memd(r0++#8) = r5:4\n",
    "  r5:4 = memd(r1+#16)\n",
    "  r1 = add(r1,#24)\n",
    "  loop0(1f,r3)\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  memd(r0++#8) = r5:4\n",
    "  r5:4 = memd(r1++#8)\n",
    " }}:endloop0\n",
    " {{\n",
    "  memd(r0) = r5:4\n",
    "  r0 -= add(r2,#-8)\n",
    "  jumpr r31\n",
    " }}\n",
".Lmemcpy_call:\n",
"jump memcpy@PLT\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_moddi3() {
        core::arch::asm!(
            "{{\n",
    "  p3 = tstbit(r1,#31)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = abs(r1:0)\n",
    "  r3:2 = abs(r3:2)\n",
    " }}\n",
    " {{\n",
    "  r6 = cl0(r1:0)\n",
    "  r7 = cl0(r3:2)\n",
    "  r5:4 = r3:2\n",
    "  r3:2 = r1:0\n",
    " }}\n",
    " {{\n",
    "  r10 = sub(r7,r6)\n",
    "  r1:0 = #0\n",
    "  r15:14 = #1\n",
    " }}\n",
    " {{\n",
    "  r11 = add(r10,#1)\n",
    "  r13:12 = lsl(r5:4,r10)\n",
    "  r15:14 = lsl(r15:14,r10)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gtu(r5:4,r3:2)\n",
    "  loop0(1f,r11)\n",
    " }}\n",
    " {{\n",
    "  if (p0) jump .hexagon_moddi3_return\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  p0 = cmp.gtu(r13:12,r3:2)\n",
    " }}\n",
    " {{\n",
    "  r7:6 = sub(r3:2, r13:12)\n",
    "  r9:8 = add(r1:0, r15:14)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = vmux(p0, r1:0, r9:8)\n",
    "  r3:2 = vmux(p0, r3:2, r7:6)\n",
    " }}\n",
    " {{\n",
    "  r15:14 = lsr(r15:14, #1)\n",
    "  r13:12 = lsr(r13:12, #1)\n",
    " }}:endloop0\n",
    "\n",
    ".hexagon_moddi3_return:\n",
    " {{\n",
    "  r1:0 = neg(r3:2)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = vmux(p3,r1:0,r3:2)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_modsi3() {
        core::arch::asm!(
            "{{\n",
    "  p2 = cmp.ge(r0,#0)\n",
    "  r2 = abs(r0)\n",
    "  r1 = abs(r1)\n",
    " }}\n",
    " {{\n",
    "  r3 = cl0(r2)\n",
    "  r4 = cl0(r1)\n",
    "  p0 = cmp.gtu(r1,r2)\n",
    " }}\n",
    " {{\n",
    "  r3 = sub(r4,r3)\n",
    "  if (p0) jumpr r31\n",
    " }}\n",
    " {{\n",
    "  p1 = cmp.eq(r3,#0)\n",
    "  loop0(1f,r3)\n",
    "  r0 = r2\n",
    "  r2 = lsl(r1,r3)\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  p0 = cmp.gtu(r2,r0)\n",
    "  if (!p0.new) r0 = sub(r0,r2)\n",
    "  r2 = lsr(r2,#1)\n",
    "  if (p1) r1 = #0\n",
    " }}:endloop0\n",
    " {{\n",
    "  p0 = cmp.gtu(r2,r0)\n",
    "  if (!p0.new) r0 = sub(r0,r1)\n",
    "  if (p2) jumpr r31\n",
    " }}\n",
    " {{\n",
    "  r0 = neg(r0)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_divsf3() {
        core::arch::asm!(
            "{{\n",
    "    r2,p0 = sfrecipa(r0,r1)\n",
    "    r4 = sffixupd(r0,r1)\n",
    "    r3 = ##0x3f800000\n",
    "  }}\n",
    "  {{\n",
    "    r5 = sffixupn(r0,r1)\n",
    "    r3 -= sfmpy(r4,r2):lib\n",
    "    r6 = ##0x80000000\n",
    "    r7 = r3\n",
    "  }}\n",
    "  {{\n",
    "    r2 += sfmpy(r3,r2):lib\n",
    "    r3 = r7\n",
    "    r6 = r5\n",
    "    r0 = and(r6,r5)\n",
    "  }}\n",
    "  {{\n",
    "    r3 -= sfmpy(r4,r2):lib\n",
    "    r0 += sfmpy(r5,r2):lib\n",
    "  }}\n",
    "  {{\n",
    "    r2 += sfmpy(r3,r2):lib\n",
    "    r6 -= sfmpy(r0,r4):lib\n",
    "  }}\n",
    "  {{\n",
    "    r0 += sfmpy(r6,r2):lib\n",
    "  }}\n",
    "  {{\n",
    "    r5 -= sfmpy(r0,r4):lib\n",
    "  }}\n",
    "  {{\n",
    "    r0 += sfmpy(r5,r2,p0):scale\n",
    "    jumpr r31\n",
    "  }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_sqrtf() {
        core::arch::asm!(
            "{{\n",
    "    r3,p0 = sfinvsqrta(r0)\n",
    "    r5 = sffixupr(r0)\n",
    "    r4 = ##0x3f000000\n",
    "    r1:0 = combine(#0,#0)\n",
    "  }}\n",
    "  {{\n",
    "    r0 += sfmpy(r3,r5):lib\n",
    "    r1 += sfmpy(r3,r4):lib\n",
    "    r2 = r4\n",
    "    r3 = r5\n",
    "  }}\n",
    "  {{\n",
    "    r2 -= sfmpy(r0,r1):lib\n",
    "    p1 = sfclass(r5,#1)\n",
    "\n",
    "  }}\n",
    "  {{\n",
    "    r0 += sfmpy(r0,r2):lib\n",
    "    r1 += sfmpy(r1,r2):lib\n",
    "    r2 = r4\n",
    "    r3 = r5\n",
    "  }}\n",
    "  {{\n",
    "    r2 -= sfmpy(r0,r1):lib\n",
    "    r3 -= sfmpy(r0,r0):lib\n",
    "  }}\n",
    "  {{\n",
    "    r0 += sfmpy(r1,r3):lib\n",
    "    r1 += sfmpy(r1,r2):lib\n",
    "    r2 = r4\n",
    "    r3 = r5\n",
    "  }}\n",
    "  {{\n",
    "\n",
    "    r3 -= sfmpy(r0,r0):lib\n",
    "    if (p1) r0 = or(r0,r5)\n",
    "  }}\n",
    "  {{\n",
    "    r0 += sfmpy(r1,r3,p0):scale\n",
    "    jumpr r31\n",
    "  }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_udivdi3() {
        core::arch::asm!(
            "{{\n",
    "  r6 = cl0(r1:0)\n",
    "  r7 = cl0(r3:2)\n",
    "  r5:4 = r3:2\n",
    "  r3:2 = r1:0\n",
    " }}\n",
    " {{\n",
    "  r10 = sub(r7,r6)\n",
    "  r1:0 = #0\n",
    "  r15:14 = #1\n",
    " }}\n",
    " {{\n",
    "  r11 = add(r10,#1)\n",
    "  r13:12 = lsl(r5:4,r10)\n",
    "  r15:14 = lsl(r15:14,r10)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gtu(r5:4,r3:2)\n",
    "  loop0(1f,r11)\n",
    " }}\n",
    " {{\n",
    "  if (p0) jumpr r31\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  p0 = cmp.gtu(r13:12,r3:2)\n",
    " }}\n",
    " {{\n",
    "  r7:6 = sub(r3:2, r13:12)\n",
    "  r9:8 = add(r1:0, r15:14)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = vmux(p0, r1:0, r9:8)\n",
    "  r3:2 = vmux(p0, r3:2, r7:6)\n",
    " }}\n",
    " {{\n",
    "  r15:14 = lsr(r15:14, #1)\n",
    "  r13:12 = lsr(r13:12, #1)\n",
    " }}:endloop0\n",
    " {{\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_udivmoddi4() {
        core::arch::asm!(
            "{{\n",
    "  r6 = cl0(r1:0)\n",
    "  r7 = cl0(r3:2)\n",
    "  r5:4 = r3:2\n",
    "  r3:2 = r1:0\n",
    " }}\n",
    " {{\n",
    "  r10 = sub(r7,r6)\n",
    "  r1:0 = #0\n",
    "  r15:14 = #1\n",
    " }}\n",
    " {{\n",
    "  r11 = add(r10,#1)\n",
    "  r13:12 = lsl(r5:4,r10)\n",
    "  r15:14 = lsl(r15:14,r10)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gtu(r5:4,r3:2)\n",
    "  loop0(1f,r11)\n",
    " }}\n",
    " {{\n",
    "  if (p0) jumpr r31\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  p0 = cmp.gtu(r13:12,r3:2)\n",
    " }}\n",
    " {{\n",
    "  r7:6 = sub(r3:2, r13:12)\n",
    "  r9:8 = add(r1:0, r15:14)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = vmux(p0, r1:0, r9:8)\n",
    "  r3:2 = vmux(p0, r3:2, r7:6)\n",
    " }}\n",
    " {{\n",
    "  r15:14 = lsr(r15:14, #1)\n",
    "  r13:12 = lsr(r13:12, #1)\n",
    " }}:endloop0\n",
    " {{\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_udivmodsi4() {
        core::arch::asm!(
            "{{\n",
    "  r2 = cl0(r0)\n",
    "  r3 = cl0(r1)\n",
    "  r5:4 = combine(#1,#0)\n",
    "  p0 = cmp.gtu(r1,r0)\n",
    " }}\n",
    " {{\n",
    "  r6 = sub(r3,r2)\n",
    "  r4 = r1\n",
    "  r1:0 = combine(r0,r4)\n",
    "  if (p0) jumpr r31\n",
    " }}\n",
    " {{\n",
    "  r3:2 = vlslw(r5:4,r6)\n",
    "  loop0(1f,r6)\n",
    "  p0 = cmp.eq(r6,#0)\n",
    "  if (p0.new) r4 = #0\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  p0 = cmp.gtu(r2,r1)\n",
    "  if (!p0.new) r1 = sub(r1,r2)\n",
    "  if (!p0.new) r0 = add(r0,r3)\n",
    "  r3:2 = vlsrw(r3:2,#1)\n",
    " }}:endloop0\n",
    " {{\n",
    "  p0 = cmp.gtu(r2,r1)\n",
    "  if (!p0.new) r1 = sub(r1,r4)\n",
    "  if (!p0.new) r0 = add(r0,r3)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_udivsi3() {
        core::arch::asm!(
            "{{\n",
    "  r2 = cl0(r0)\n",
    "  r3 = cl0(r1)\n",
    "  r5:4 = combine(#1,#0)\n",
    "  p0 = cmp.gtu(r1,r0)\n",
    " }}\n",
    " {{\n",
    "  r6 = sub(r3,r2)\n",
    "  r4 = r1\n",
    "  r1:0 = combine(r0,r4)\n",
    "  if (p0) jumpr r31\n",
    " }}\n",
    " {{\n",
    "  r3:2 = vlslw(r5:4,r6)\n",
    "  loop0(1f,r6)\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  p0 = cmp.gtu(r2,r1)\n",
    "  if (!p0.new) r1 = sub(r1,r2)\n",
    "  if (!p0.new) r0 = add(r0,r3)\n",
    "  r3:2 = vlsrw(r3:2,#1)\n",
    " }}:endloop0\n",
    " {{\n",
    "  p0 = cmp.gtu(r2,r1)\n",
    "  if (!p0.new) r0 = add(r0,r3)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_umoddi3() {
        core::arch::asm!(
            "{{\n",
    "  r6 = cl0(r1:0)\n",
    "  r7 = cl0(r3:2)\n",
    "  r5:4 = r3:2\n",
    "  r3:2 = r1:0\n",
    " }}\n",
    " {{\n",
    "  r10 = sub(r7,r6)\n",
    "  r1:0 = #0\n",
    "  r15:14 = #1\n",
    " }}\n",
    " {{\n",
    "  r11 = add(r10,#1)\n",
    "  r13:12 = lsl(r5:4,r10)\n",
    "  r15:14 = lsl(r15:14,r10)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gtu(r5:4,r3:2)\n",
    "  loop0(1f,r11)\n",
    " }}\n",
    " {{\n",
    "  if (p0) jump .hexagon_umoddi3_return\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  p0 = cmp.gtu(r13:12,r3:2)\n",
    " }}\n",
    " {{\n",
    "  r7:6 = sub(r3:2, r13:12)\n",
    "  r9:8 = add(r1:0, r15:14)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = vmux(p0, r1:0, r9:8)\n",
    "  r3:2 = vmux(p0, r3:2, r7:6)\n",
    " }}\n",
    " {{\n",
    "  r15:14 = lsr(r15:14, #1)\n",
    "  r13:12 = lsr(r13:12, #1)\n",
    " }}:endloop0\n",
    "\n",
    ".hexagon_umoddi3_return:\n",
    " {{\n",
    "  r1:0 = r3:2\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_umodsi3() {
        core::arch::asm!(
            "{{\n",
    "  r2 = cl0(r0)\n",
    "  r3 = cl0(r1)\n",
    "  p0 = cmp.gtu(r1,r0)\n",
    " }}\n",
    " {{\n",
    "  r2 = sub(r3,r2)\n",
    "  if (p0) jumpr r31\n",
    " }}\n",
    " {{\n",
    "  loop0(1f,r2)\n",
    "  p1 = cmp.eq(r2,#0)\n",
    "  r2 = lsl(r1,r2)\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  p0 = cmp.gtu(r2,r0)\n",
    "  if (!p0.new) r0 = sub(r0,r2)\n",
    "  r2 = lsr(r2,#1)\n",
    "  if (p1) r1 = #0\n",
    " }}:endloop0\n",
    " {{\n",
    "  p0 = cmp.gtu(r2,r0)\n",
    "  if (!p0.new) r0 = sub(r0,r1)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_adddf3() {
        core::arch::asm!(
    " .set __qdsp_adddf3, __hexagon_adddf3\n",
    " .global __qdsp_adddf3\n",
    " .set __hexagon_fast_adddf3, __hexagon_adddf3\n",
    " .set __hexagon_fast2_adddf3, __hexagon_adddf3\n",
    " .set __qdsp_subdf3, __hexagon_subdf3\n",
    " .set __hexagon_fast_subdf3, __hexagon_subdf3\n",
    " .set __hexagon_fast2_subdf3, __hexagon_subdf3\n",
    "\n",
    " .p2align 5\n",
    " {{\n",
    "  r4 = extractu(r1,#11,#20)\n",
    "  r5 = extractu(r3,#11,#20)\n",
    "  r13:12 = combine(##0x20000000,#0)\n",
    " }}\n",
    " {{\n",
    "  p3 = dfclass(r1:0,#2)\n",
    "  p3 = dfclass(r3:2,#2)\n",
    "  r9:8 = r13:12\n",
    "  p2 = cmp.gtu(r5,r4)\n",
    " }}\n",
    " {{\n",
    "  if (!p3) jump .Ladd_abnormal\n",
    "  if (p2) r1:0 = r3:2\n",
    "  if (p2) r3:2 = r1:0\n",
    "  if (p2) r5:4 = combine(r4,r5)\n",
    " }}\n",
    " {{\n",
    "  r13:12 = insert(r1:0,#52,#11 -2)\n",
    "  r9:8 = insert(r3:2,#52,#11 -2)\n",
    "  r15 = sub(r4,r5)\n",
    "  r7:6 = combine(#62,#1)\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".Ladd_continue:\n",
    " {{\n",
    "  r15 = min(r15,r7)\n",
    "\n",
    "  r11:10 = neg(r13:12)\n",
    "  p2 = cmp.gt(r1,#-1)\n",
    "  r14 = #0\n",
    " }}\n",
    " {{\n",
    "  if (!p2) r13:12 = r11:10\n",
    "  r11:10 = extractu(r9:8,r15:14)\n",
    "  r9:8 = ASR(r9:8,r15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  r15:14 = #0\n",
    " }}\n",
    " {{\n",
    "  p1 = cmp.eq(r11:10,r15:14)\n",
    "  if (!p1.new) r8 = or(r8,r6)\n",
    "  r5 = add(r4,#-1024 -60)\n",
    "  p3 = cmp.gt(r3,#-1)\n",
    " }}\n",
    " {{\n",
    "  r13:12 = add(r13:12,r9:8)\n",
    "  r11:10 = sub(r13:12,r9:8)\n",
    "  r7:6 = combine(#54,##2045)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gtu(r4,r7)\n",
    "  p0 = !cmp.gtu(r4,r6)\n",
    "  if (!p0.new) jump:nt .Ladd_ovf_unf\n",
    "  if (!p3) r13:12 = r11:10\n",
    " }}\n",
    " {{\n",
    "  r1:0 = convert_d2df(r13:12)\n",
    "  p0 = cmp.eq(r13,#0)\n",
    "  p0 = cmp.eq(r12,#0)\n",
    "  if (p0.new) jump:nt .Ladd_zero\n",
    " }}\n",
    " {{\n",
    "  r1 += asl(r5,#20)\n",
    "  jumpr r31\n",
    " }}\n",
    " .falign\n",
    //"__hexagon_subdf3:\n",
    " {{\n",
    "  r3 = togglebit(r3,#31)\n",
    "  jump __qdsp_adddf3\n",
    " }}\n",
    "\n",
    "\n",
    " .falign\n",
    ".Ladd_zero:\n",
    "\n",
    "\n",
    " {{\n",
    "  r28 = USR\n",
    "  r1:0 = #0\n",
    "  r3 = #1\n",
    " }}\n",
    " {{\n",
    "  r28 = extractu(r28,#2,#22)\n",
    "  r3 = asl(r3,#31)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.eq(r28,#2)\n",
    "  if (p0.new) r1 = xor(r1,r3)\n",
    "  jumpr r31\n",
    " }}\n",
    " .falign\n",
    ".Ladd_ovf_unf:\n",
    " {{\n",
    "  r1:0 = convert_d2df(r13:12)\n",
    "  p0 = cmp.eq(r13,#0)\n",
    "  p0 = cmp.eq(r12,#0)\n",
    "  if (p0.new) jump:nt .Ladd_zero\n",
    " }}\n",
    " {{\n",
    "  r28 = extractu(r1,#11,#20)\n",
    "  r1 += asl(r5,#20)\n",
    " }}\n",
    " {{\n",
    "  r5 = add(r5,r28)\n",
    "  r3:2 = combine(##0x00100000,#0)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gt(r5,##1024 +1024 -2)\n",
    "  if (p0.new) jump:nt .Ladd_ovf\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gt(r5,#0)\n",
    "  if (p0.new) jumpr:t r31\n",
    "  r28 = sub(#1,r5)\n",
    " }}\n",
    " {{\n",
    "  r3:2 = insert(r1:0,#52,#0)\n",
    "  r1:0 = r13:12\n",
    " }}\n",
    " {{\n",
    "  r3:2 = lsr(r3:2,r28)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = insert(r3:2,#63,#0)\n",
    "  jumpr r31\n",
    " }}\n",
    " .falign\n",
    ".Ladd_ovf:\n",
    "\n",
    " {{\n",
    "  r1:0 = r13:12\n",
    "  r28 = USR\n",
    "  r13:12 = combine(##0x7fefffff,#-1)\n",
    " }}\n",
    " {{\n",
    "  r5 = extractu(r28,#2,#22)\n",
    "  r28 = or(r28,#0x28)\n",
    "  r9:8 = combine(##0x7ff00000,#0)\n",
    " }}\n",
    " {{\n",
    "  USR = r28\n",
    "  r5 ^= lsr(r1,#31)\n",
    "  r28 = r5\n",
    " }}\n",
    " {{\n",
    "  p0 = !cmp.eq(r28,#1)\n",
    "  p0 = !cmp.eq(r5,#2)\n",
    "  if (p0.new) r13:12 = r9:8\n",
    " }}\n",
    " {{\n",
    "  r1:0 = insert(r13:12,#63,#0)\n",
    " }}\n",
    " {{\n",
    "  p0 = dfcmp.eq(r1:0,r1:0)\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    ".Ladd_abnormal:\n",
    " {{\n",
    "  r13:12 = extractu(r1:0,#63,#0)\n",
    "  r9:8 = extractu(r3:2,#63,#0)\n",
    " }}\n",
    " {{\n",
    "  p3 = cmp.gtu(r13:12,r9:8)\n",
    "  if (!p3.new) r1:0 = r3:2\n",
    "  if (!p3.new) r3:2 = r1:0\n",
    " }}\n",
    " {{\n",
    "\n",
    "  p0 = dfclass(r1:0,#0x0f)\n",
    "  if (!p0.new) jump:nt .Linvalid_nan_add\n",
    "  if (!p3) r13:12 = r9:8\n",
    "  if (!p3) r9:8 = r13:12\n",
    " }}\n",
    " {{\n",
    "\n",
    "\n",
    "  p1 = dfclass(r1:0,#0x08)\n",
    "  if (p1.new) jump:nt .Linf_add\n",
    " }}\n",
    " {{\n",
    "  p2 = dfclass(r3:2,#0x01)\n",
    "  if (p2.new) jump:nt .LB_zero\n",
    "  r13:12 = #0\n",
    " }}\n",
    "\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#4)\n",
    "  if (p0.new) jump:nt .Ladd_two_subnormal\n",
    "  r13:12 = combine(##0x20000000,#0)\n",
    " }}\n",
    " {{\n",
    "  r4 = extractu(r1,#11,#20)\n",
    "  r5 = #1\n",
    "\n",
    "  r9:8 = asl(r9:8,#11 -2)\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  r13:12 = insert(r1:0,#52,#11 -2)\n",
    "  r15 = sub(r4,r5)\n",
    "  r7:6 = combine(#62,#1)\n",
    "  jump .Ladd_continue\n",
    " }}\n",
    "\n",
    ".Ladd_two_subnormal:\n",
    " {{\n",
    "  r13:12 = extractu(r1:0,#63,#0)\n",
    "  r9:8 = extractu(r3:2,#63,#0)\n",
    " }}\n",
    " {{\n",
    "  r13:12 = neg(r13:12)\n",
    "  r9:8 = neg(r9:8)\n",
    "  p0 = cmp.gt(r1,#-1)\n",
    "  p1 = cmp.gt(r3,#-1)\n",
    " }}\n",
    " {{\n",
    "  if (p0) r13:12 = r1:0\n",
    "  if (p1) r9:8 = r3:2\n",
    " }}\n",
    " {{\n",
    "  r13:12 = add(r13:12,r9:8)\n",
    " }}\n",
    " {{\n",
    "  r9:8 = neg(r13:12)\n",
    "  p0 = cmp.gt(r13,#-1)\n",
    "  r3:2 = #0\n",
    " }}\n",
    " {{\n",
    "  if (!p0) r1:0 = r9:8\n",
    "  if (p0) r1:0 = r13:12\n",
    "  r3 = ##0x80000000\n",
    " }}\n",
    " {{\n",
    "  if (!p0) r1 = or(r1,r3)\n",
    "  p0 = dfcmp.eq(r1:0,r3:2)\n",
    "  if (p0.new) jump:nt .Lzero_plus_zero0\n",
    " }}\n",
    " {{\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    ".Linvalid_nan_add:\n",
    " {{\n",
    "  r28 = convert_df2sf(r1:0)\n",
    "  p0 = dfclass(r3:2,#0x0f)\n",
    "  if (p0.new) r3:2 = r1:0\n",
    " }}\n",
    " {{\n",
    "  r2 = convert_df2sf(r3:2)\n",
    "  r1:0 = #-1\n",
    "  jumpr r31\n",
    " }}\n",
    " .falign\n",
    ".LB_zero:\n",
    " {{\n",
    "  p0 = dfcmp.eq(r13:12,r1:0)\n",
    "  if (!p0.new) jumpr:t r31\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".Lzero_plus_zero0:\n",
    " {{\n",
    "  p0 = cmp.eq(r1:0,r3:2)\n",
    "  if (p0.new) jumpr:t r31\n",
    " }}\n",
    " {{\n",
    "  r28 = USR\n",
    " }}\n",
    " {{\n",
    "  r28 = extractu(r28,#2,#22)\n",
    "  r1:0 = #0\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.eq(r28,#2)\n",
    "  if (p0.new) r1 = ##0x80000000\n",
    "  jumpr r31\n",
    " }}\n",
    ".Linf_add:\n",
    "\n",
    " {{\n",
    "  p0 = !cmp.eq(r1,r3)\n",
    "  p0 = dfclass(r3:2,#8)\n",
    "  if (!p0.new) jumpr:t r31\n",
    " }}\n",
    " {{\n",
    "  r2 = ##0x7f800001\n",
    " }}\n",
    " {{\n",
    "  r1:0 = convert_sf2df(r2)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_divdf3() {
        core::arch::asm!(
    " .set __qdsp_divdf3, __hexagon_divdf3\n",
    " .set __hexagon_fast_divdf3, __hexagon_divdf3\n",
    " .set __hexagon_fast2_divdf3, __hexagon_divdf3\n",
    " .p2align 5\n",
    " {{\n",
    "  p2 = dfclass(r1:0,#0x02)\n",
    "  p2 = dfclass(r3:2,#0x02)\n",
    "  r13:12 = combine(r3,r1)\n",
    "  r28 = xor(r1,r3)\n",
    " }}\n",
    " {{\n",
    "  if (!p2) jump .Ldiv_abnormal\n",
    "  r7:6 = extractu(r3:2,#23,#52 -23)\n",
    "  r8 = ##0x3f800001\n",
    " }}\n",
    " {{\n",
    "  r9 = or(r8,r6)\n",
    "  r13 = extractu(r13,#11,#52 -32)\n",
    "  r12 = extractu(r12,#11,#52 -32)\n",
    "  p3 = cmp.gt(r28,#-1)\n",
    " }}\n",
    "\n",
    "\n",
    ".Ldenorm_continue:\n",
    " {{\n",
    "  r11,p0 = sfrecipa(r8,r9)\n",
    "  r10 = and(r8,#-2)\n",
    "  r28 = #1\n",
    "  r12 = sub(r12,r13)\n",
    " }}\n",
    "\n",
    "\n",
    " {{\n",
    "  r10 -= sfmpy(r11,r9):lib\n",
    "  r1 = insert(r28,#11 +1,#52 -32)\n",
    "  r13 = ##0x00800000 << 3\n",
    " }}\n",
    " {{\n",
    "  r11 += sfmpy(r11,r10):lib\n",
    "  r3 = insert(r28,#11 +1,#52 -32)\n",
    "  r10 = and(r8,#-2)\n",
    " }}\n",
    " {{\n",
    "  r10 -= sfmpy(r11,r9):lib\n",
    "  r5 = #-0x3ff +1\n",
    "  r4 = #0x3ff -1\n",
    " }}\n",
    " {{\n",
    "  r11 += sfmpy(r11,r10):lib\n",
    "  p1 = cmp.gt(r12,r5)\n",
    "  p1 = !cmp.gt(r12,r4)\n",
    " }}\n",
    " {{\n",
    "  r13 = insert(r11,#23,#3)\n",
    "  r5:4 = #0\n",
    "  r12 = add(r12,#-61)\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  r13 = add(r13,#((-3) << 3))\n",
    " }}\n",
    " {{ r7:6 = mpyu(r13,r1); r1:0 = asl(r1:0,# ( 15 )); }}; {{ r6 = # 0; r1:0 -= mpyu(r7,r2); r15:14 = mpyu(r7,r3); }}; {{ r5:4 += ASL(r7:6, # ( 14 )); r1:0 -= asl(r15:14, # 32); }}\n",
    " {{ r7:6 = mpyu(r13,r1); r1:0 = asl(r1:0,# ( 15 )); }}; {{ r6 = # 0; r1:0 -= mpyu(r7,r2); r15:14 = mpyu(r7,r3); }}; {{ r5:4 += ASR(r7:6, # ( 1 )); r1:0 -= asl(r15:14, # 32); }}\n",
    " {{ r7:6 = mpyu(r13,r1); r1:0 = asl(r1:0,# ( 15 )); }}; {{ r6 = # 0; r1:0 -= mpyu(r7,r2); r15:14 = mpyu(r7,r3); }}; {{ r5:4 += ASR(r7:6, # ( 16 )); r1:0 -= asl(r15:14, # 32); }}\n",
    " {{ r7:6 = mpyu(r13,r1); r1:0 = asl(r1:0,# ( 15 )); }}; {{ r6 = # 0; r1:0 -= mpyu(r7,r2); r15:14 = mpyu(r7,r3); }}; {{ r5:4 += ASR(r7:6, # ( 31 )); r1:0 -= asl(r15:14, # 32); r7:6=# ( 0 ); }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "\n",
    "  r15:14 = sub(r1:0,r3:2)\n",
    "  p0 = cmp.gtu(r3:2,r1:0)\n",
    "\n",
    "  if (!p0.new) r6 = #2\n",
    " }}\n",
    " {{\n",
    "  r5:4 = add(r5:4,r7:6)\n",
    "  if (!p0) r1:0 = r15:14\n",
    "  r15:14 = #0\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.eq(r1:0,r15:14)\n",
    "  if (!p0.new) r4 = or(r4,r28)\n",
    " }}\n",
    " {{\n",
    "  r7:6 = neg(r5:4)\n",
    " }}\n",
    " {{\n",
    "  if (!p3) r5:4 = r7:6\n",
    " }}\n",
    " {{\n",
    "  r1:0 = convert_d2df(r5:4)\n",
    "  if (!p1) jump .Ldiv_ovf_unf\n",
    " }}\n",
    " {{\n",
    "  r1 += asl(r12,#52 -32)\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    ".Ldiv_ovf_unf:\n",
    " {{\n",
    "  r1 += asl(r12,#52 -32)\n",
    "  r13 = extractu(r1,#11,#52 -32)\n",
    " }}\n",
    " {{\n",
    "  r7:6 = abs(r5:4)\n",
    "  r12 = add(r12,r13)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gt(r12,##0x3ff +0x3ff)\n",
    "  if (p0.new) jump:nt .Ldiv_ovf\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gt(r12,#0)\n",
    "  if (p0.new) jump:nt .Lpossible_unf2\n",
    " }}\n",
    " {{\n",
    "  r13 = add(clb(r7:6),#-1)\n",
    "  r12 = sub(#7,r12)\n",
    "  r10 = USR\n",
    "  r11 = #63\n",
    " }}\n",
    " {{\n",
    "  r13 = min(r12,r11)\n",
    "  r11 = or(r10,#0x030)\n",
    "  r7:6 = asl(r7:6,r13)\n",
    "  r12 = #0\n",
    " }}\n",
    " {{\n",
    "  r15:14 = extractu(r7:6,r13:12)\n",
    "  r7:6 = lsr(r7:6,r13)\n",
    "  r3:2 = #1\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gtu(r3:2,r15:14)\n",
    "  if (!p0.new) r6 = or(r2,r6)\n",
    "  r7 = setbit(r7,#52 -32+4)\n",
    " }}\n",
    " {{\n",
    "  r5:4 = neg(r7:6)\n",
    "  p0 = bitsclr(r6,#(1<<4)-1)\n",
    "  if (!p0.new) r10 = r11\n",
    " }}\n",
    " {{\n",
    "  USR = r10\n",
    "  if (p3) r5:4 = r7:6\n",
    "  r10 = #-0x3ff -(52 +4)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = convert_d2df(r5:4)\n",
    " }}\n",
    " {{\n",
    "  r1 += asl(r10,#52 -32)\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    "\n",
    ".Lpossible_unf2:\n",
    "\n",
    "\n",
    " {{\n",
    "  r3:2 = extractu(r1:0,#63,#0)\n",
    "  r15:14 = combine(##0x00100000,#0)\n",
    "  r10 = #0x7FFF\n",
    " }}\n",
    " {{\n",
    "  p0 = dfcmp.eq(r15:14,r3:2)\n",
    "  p0 = bitsset(r7,r10)\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  if (!p0) jumpr r31\n",
    "  r10 = USR\n",
    " }}\n",
    "\n",
    " {{\n",
    "  r10 = or(r10,#0x30)\n",
    " }}\n",
    " {{\n",
    "  USR = r10\n",
    " }}\n",
    " {{\n",
    "  p0 = dfcmp.eq(r1:0,r1:0)\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    ".Ldiv_ovf:\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  r10 = USR\n",
    "  r3:2 = combine(##0x7fefffff,#-1)\n",
    "  r1 = mux(p3,#0,#-1)\n",
    " }}\n",
    " {{\n",
    "  r7:6 = combine(##0x7ff00000,#0)\n",
    "  r5 = extractu(r10,#2,#22)\n",
    "  r10 = or(r10,#0x28)\n",
    " }}\n",
    " {{\n",
    "  USR = r10\n",
    "  r5 ^= lsr(r1,#31)\n",
    "  r4 = r5\n",
    " }}\n",
    " {{\n",
    "  p0 = !cmp.eq(r4,#1)\n",
    "  p0 = !cmp.eq(r5,#2)\n",
    "  if (p0.new) r3:2 = r7:6\n",
    "  p0 = dfcmp.eq(r3:2,r3:2)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = insert(r3:2,#63,#0)\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".Ldiv_abnormal:\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#0x0F)\n",
    "  p0 = dfclass(r3:2,#0x0F)\n",
    "  p3 = cmp.gt(r28,#-1)\n",
    " }}\n",
    " {{\n",
    "  p1 = dfclass(r1:0,#0x08)\n",
    "  p1 = dfclass(r3:2,#0x08)\n",
    " }}\n",
    " {{\n",
    "  p2 = dfclass(r1:0,#0x01)\n",
    "  p2 = dfclass(r3:2,#0x01)\n",
    " }}\n",
    " {{\n",
    "  if (!p0) jump .Ldiv_nan\n",
    "  if (p1) jump .Ldiv_invalid\n",
    " }}\n",
    " {{\n",
    "  if (p2) jump .Ldiv_invalid\n",
    " }}\n",
    " {{\n",
    "  p2 = dfclass(r1:0,#(0x0F ^ 0x01))\n",
    "  p2 = dfclass(r3:2,#(0x0F ^ 0x08))\n",
    " }}\n",
    " {{\n",
    "  p1 = dfclass(r1:0,#(0x0F ^ 0x08))\n",
    "  p1 = dfclass(r3:2,#(0x0F ^ 0x01))\n",
    " }}\n",
    " {{\n",
    "  if (!p2) jump .Ldiv_zero_result\n",
    "  if (!p1) jump .Ldiv_inf_result\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#0x02)\n",
    "  p1 = dfclass(r3:2,#0x02)\n",
    "  r10 = ##0x00100000\n",
    " }}\n",
    " {{\n",
    "  r13:12 = combine(r3,r1)\n",
    "  r1 = insert(r10,#11 +1,#52 -32)\n",
    "  r3 = insert(r10,#11 +1,#52 -32)\n",
    " }}\n",
    " {{\n",
    "  if (p0) r1 = or(r1,r10)\n",
    "  if (p1) r3 = or(r3,r10)\n",
    " }}\n",
    " {{\n",
    "  r5 = add(clb(r1:0),#-11)\n",
    "  r4 = add(clb(r3:2),#-11)\n",
    "  r10 = #1\n",
    " }}\n",
    " {{\n",
    "  r12 = extractu(r12,#11,#52 -32)\n",
    "  r13 = extractu(r13,#11,#52 -32)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = asl(r1:0,r5)\n",
    "  r3:2 = asl(r3:2,r4)\n",
    "  if (!p0) r12 = sub(r10,r5)\n",
    "  if (!p1) r13 = sub(r10,r4)\n",
    " }}\n",
    " {{\n",
    "  r7:6 = extractu(r3:2,#23,#52 -23)\n",
    " }}\n",
    " {{\n",
    "  r9 = or(r8,r6)\n",
    "  jump .Ldenorm_continue\n",
    " }}\n",
    "\n",
    ".Ldiv_zero_result:\n",
    " {{\n",
    "  r1 = xor(r1,r3)\n",
    "  r3:2 = #0\n",
    " }}\n",
    " {{\n",
    "  r1:0 = insert(r3:2,#63,#0)\n",
    "  jumpr r31\n",
    " }}\n",
    ".Ldiv_inf_result:\n",
    " {{\n",
    "  p2 = dfclass(r3:2,#0x01)\n",
    "  p2 = dfclass(r1:0,#(0x0F ^ 0x08))\n",
    " }}\n",
    " {{\n",
    "  r10 = USR\n",
    "  if (!p2) jump 1f\n",
    "  r1 = xor(r1,r3)\n",
    " }}\n",
    " {{\n",
    "  r10 = or(r10,#0x04)\n",
    " }}\n",
    " {{\n",
    "  USR = r10\n",
    " }}\n",
    "1:\n",
    " {{\n",
    "  r3:2 = combine(##0x7ff00000,#0)\n",
    "  p0 = dfcmp.uo(r3:2,r3:2)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = insert(r3:2,#63,#0)\n",
    "  jumpr r31\n",
    " }}\n",
    ".Ldiv_nan:\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#0x10)\n",
    "  p1 = dfclass(r3:2,#0x10)\n",
    "  if (!p0.new) r1:0 = r3:2\n",
    "  if (!p1.new) r3:2 = r1:0\n",
    " }}\n",
    " {{\n",
    "  r5 = convert_df2sf(r1:0)\n",
    "  r4 = convert_df2sf(r3:2)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = #-1\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    ".Ldiv_invalid:\n",
    " {{\n",
    "  r10 = ##0x7f800001\n",
    " }}\n",
    " {{\n",
    "  r1:0 = convert_sf2df(r10)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_mindf3() {
        core::arch::asm!(
    "  .set __qdsp_mindf3, __hexagon_mindf3\n",
    "  .set __qdsp_maxdf3, __hexagon_maxdf3\n",
    " .p2align 5\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#0x10)\n",
    "  p1 = dfcmp.gt(r1:0,r3:2)\n",
    "  r5:4 = r1:0\n",
    " }}\n",
    " {{\n",
    "  if (p0) r1:0 = r3:2\n",
    "  if (p1) r1:0 = r3:2\n",
    "  p2 = dfcmp.eq(r1:0,r3:2)\n",
    "  if (!p2.new) jumpr:t r31\n",
    " }}\n",
    "\n",
    " {{\n",
    "  r1:0 = or(r5:4,r3:2)\n",
    "  jumpr r31\n",
    " }}\n",
    " .falign\n",
    //"__hexagon_maxdf3:\n",
    //"fmax:\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#0x10)\n",
    "  p1 = dfcmp.gt(r3:2,r1:0)\n",
    "  r5:4 = r1:0\n",
    " }}\n",
    " {{\n",
    "  if (p0) r1:0 = r3:2\n",
    "  if (p1) r1:0 = r3:2\n",
    "  p2 = dfcmp.eq(r1:0,r3:2)\n",
    "  if (!p2.new) jumpr:t r31\n",
    " }}\n",
    "\n",
    " {{\n",
    "  r1:0 = and(r5:4,r3:2)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_muldf3() {
        core::arch::asm!(
    " .set __qdsp_muldf3, __hexagon_muldf3\n",
    " .set __hexagon_fast_muldf3, __hexagon_muldf3\n",
    " .set __hexagon_fast2_muldf3, __hexagon_muldf3\n",
    " .p2align 5\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#2)\n",
    "  p0 = dfclass(r3:2,#2)\n",
    "  r13:12 = combine(##0x40000000,#0)\n",
    " }}\n",
    " {{\n",
    "  r13:12 = insert(r1:0,#52,#11 -1)\n",
    "  r5:4 = asl(r3:2,#11 -1)\n",
    "  r28 = #-1024\n",
    "  r9:8 = #1\n",
    " }}\n",
    " {{\n",
    "  r7:6 = mpyu(r4,r13)\n",
    "  r5:4 = insert(r9:8,#2,#62)\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  r15:14 = mpyu(r12,r4)\n",
    "  r7:6 += mpyu(r12,r5)\n",
    " }}\n",
    " {{\n",
    "  r7:6 += lsr(r15:14,#32)\n",
    "  r11:10 = mpyu(r13,r5)\n",
    "  r5:4 = combine(##1024 +1024 -4,#0)\n",
    " }}\n",
    " {{\n",
    "  r11:10 += lsr(r7:6,#32)\n",
    "  if (!p0) jump .Lmul_abnormal\n",
    "  p1 = cmp.eq(r14,#0)\n",
    "  p1 = cmp.eq(r6,#0)\n",
    " }}\n",
    " {{\n",
    "  if (!p1) r10 = or(r10,r8)\n",
    "  r6 = extractu(r1,#11,#20)\n",
    "  r7 = extractu(r3,#11,#20)\n",
    " }}\n",
    " {{\n",
    "  r15:14 = neg(r11:10)\n",
    "  r6 += add(r28,r7)\n",
    "  r28 = xor(r1,r3)\n",
    " }}\n",
    " {{\n",
    "  if (!p2.new) r11:10 = r15:14\n",
    "  p2 = cmp.gt(r28,#-1)\n",
    "  p0 = !cmp.gt(r6,r5)\n",
    "  p0 = cmp.gt(r6,r4)\n",
    "  if (!p0.new) jump:nt .Lmul_ovf_unf\n",
    " }}\n",
    " {{\n",
    "  r1:0 = convert_d2df(r11:10)\n",
    "  r6 = add(r6,#-1024 -58)\n",
    " }}\n",
    " {{\n",
    "  r1 += asl(r6,#20)\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    " .falign\n",
    ".Lpossible_unf0:\n",
    " {{\n",
    "  p0 = cmp.eq(r0,#0)\n",
    "  p0 = bitsclr(r1,r4)\n",
    "  if (!p0.new) jumpr:t r31\n",
    "  r5 = #0x7fff\n",
    " }}\n",
    " {{\n",
    "  p0 = bitsset(r13,r5)\n",
    "  r4 = USR\n",
    "  r5 = #0x030\n",
    " }}\n",
    " {{\n",
    "  if (p0) r4 = or(r4,r5)\n",
    " }}\n",
    " {{\n",
    "  USR = r4\n",
    " }}\n",
    " {{\n",
    "  p0 = dfcmp.eq(r1:0,r1:0)\n",
    "  jumpr r31\n",
    " }}\n",
    " .falign\n",
    ".Lmul_ovf_unf:\n",
    " {{\n",
    "  r1:0 = convert_d2df(r11:10)\n",
    "  r13:12 = abs(r11:10)\n",
    "  r7 = add(r6,#-1024 -58)\n",
    " }}\n",
    " {{\n",
    "  r1 += asl(r7,#20)\n",
    "  r7 = extractu(r1,#11,#20)\n",
    "  r4 = ##0x7FEFFFFF\n",
    " }}\n",
    " {{\n",
    "  r7 += add(r6,##-1024 -58)\n",
    "\n",
    "  r5 = #0\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gt(r7,##1024 +1024 -2)\n",
    "  if (p0.new) jump:nt .Lmul_ovf\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gt(r7,#0)\n",
    "  if (p0.new) jump:nt .Lpossible_unf0\n",
    "  r5 = sub(r6,r5)\n",
    "  r28 = #63\n",
    " }}\n",
    " {{\n",
    "  r4 = #0\n",
    "  r5 = sub(#5,r5)\n",
    " }}\n",
    " {{\n",
    "  p3 = cmp.gt(r11,#-1)\n",
    "  r5 = min(r5,r28)\n",
    "  r11:10 = r13:12\n",
    " }}\n",
    " {{\n",
    "  r28 = USR\n",
    "  r15:14 = extractu(r11:10,r5:4)\n",
    " }}\n",
    " {{\n",
    "  r11:10 = asr(r11:10,r5)\n",
    "  r4 = #0x0030\n",
    "  r1 = insert(r9,#11,#20)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gtu(r9:8,r15:14)\n",
    "  if (!p0.new) r10 = or(r10,r8)\n",
    "  r11 = setbit(r11,#20 +3)\n",
    " }}\n",
    " {{\n",
    "  r15:14 = neg(r11:10)\n",
    "  p1 = bitsclr(r10,#0x7)\n",
    "  if (!p1.new) r28 = or(r4,r28)\n",
    " }}\n",
    " {{\n",
    "  if (!p3) r11:10 = r15:14\n",
    "  USR = r28\n",
    " }}\n",
    " {{\n",
    "  r1:0 = convert_d2df(r11:10)\n",
    "  p0 = dfcmp.eq(r1:0,r1:0)\n",
    " }}\n",
    " {{\n",
    "  r1 = insert(r9,#11 -1,#20 +1)\n",
    "  jumpr r31\n",
    " }}\n",
    " .falign\n",
    ".Lmul_ovf:\n",
    "\n",
    " {{\n",
    "  r28 = USR\n",
    "  r13:12 = combine(##0x7fefffff,#-1)\n",
    "  r1:0 = r11:10\n",
    " }}\n",
    " {{\n",
    "  r14 = extractu(r28,#2,#22)\n",
    "  r28 = or(r28,#0x28)\n",
    "  r5:4 = combine(##0x7ff00000,#0)\n",
    " }}\n",
    " {{\n",
    "  USR = r28\n",
    "  r14 ^= lsr(r1,#31)\n",
    "  r28 = r14\n",
    " }}\n",
    " {{\n",
    "  p0 = !cmp.eq(r28,#1)\n",
    "  p0 = !cmp.eq(r14,#2)\n",
    "  if (p0.new) r13:12 = r5:4\n",
    "  p0 = dfcmp.eq(r1:0,r1:0)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = insert(r13:12,#63,#0)\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    ".Lmul_abnormal:\n",
    " {{\n",
    "  r13:12 = extractu(r1:0,#63,#0)\n",
    "  r5:4 = extractu(r3:2,#63,#0)\n",
    " }}\n",
    " {{\n",
    "  p3 = cmp.gtu(r13:12,r5:4)\n",
    "  if (!p3.new) r1:0 = r3:2\n",
    "  if (!p3.new) r3:2 = r1:0\n",
    " }}\n",
    " {{\n",
    "\n",
    "  p0 = dfclass(r1:0,#0x0f)\n",
    "  if (!p0.new) jump:nt .Linvalid_nan\n",
    "  if (!p3) r13:12 = r5:4\n",
    "  if (!p3) r5:4 = r13:12\n",
    " }}\n",
    " {{\n",
    "\n",
    "  p1 = dfclass(r1:0,#0x08)\n",
    "  p1 = dfclass(r3:2,#0x0e)\n",
    " }}\n",
    " {{\n",
    "\n",
    "\n",
    "  p0 = dfclass(r1:0,#0x08)\n",
    "  p0 = dfclass(r3:2,#0x01)\n",
    " }}\n",
    " {{\n",
    "  if (p1) jump .Ltrue_inf\n",
    "  p2 = dfclass(r3:2,#0x01)\n",
    " }}\n",
    " {{\n",
    "  if (p0) jump .Linvalid_zeroinf\n",
    "  if (p2) jump .Ltrue_zero\n",
    "  r28 = ##0x7c000000\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  p0 = bitsclr(r1,r28)\n",
    "  if (p0.new) jump:nt .Lmul_tiny\n",
    " }}\n",
    " {{\n",
    "  r28 = cl0(r5:4)\n",
    " }}\n",
    " {{\n",
    "  r28 = add(r28,#-11)\n",
    " }}\n",
    " {{\n",
    "  r5:4 = asl(r5:4,r28)\n",
    " }}\n",
    " {{\n",
    "  r3:2 = insert(r5:4,#63,#0)\n",
    "  r1 -= asl(r28,#20)\n",
    " }}\n",
    " jump __hexagon_muldf3\n",
    ".Lmul_tiny:\n",
    " {{\n",
    "  r28 = USR\n",
    "  r1:0 = xor(r1:0,r3:2)\n",
    " }}\n",
    " {{\n",
    "  r28 = or(r28,#0x30)\n",
    "  r1:0 = insert(r9:8,#63,#0)\n",
    "  r5 = extractu(r28,#2,#22)\n",
    " }}\n",
    " {{\n",
    "  USR = r28\n",
    "  p0 = cmp.gt(r5,#1)\n",
    "  if (!p0.new) r0 = #0\n",
    "  r5 ^= lsr(r1,#31)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.eq(r5,#3)\n",
    "  if (!p0.new) r0 = #0\n",
    "  jumpr r31\n",
    " }}\n",
    ".Linvalid_zeroinf:\n",
    " {{\n",
    "  r28 = USR\n",
    " }}\n",
    " {{\n",
    "  r1:0 = #-1\n",
    "  r28 = or(r28,#2)\n",
    " }}\n",
    " {{\n",
    "  USR = r28\n",
    " }}\n",
    " {{\n",
    "  p0 = dfcmp.uo(r1:0,r1:0)\n",
    "  jumpr r31\n",
    " }}\n",
    ".Linvalid_nan:\n",
    " {{\n",
    "  p0 = dfclass(r3:2,#0x0f)\n",
    "  r28 = convert_df2sf(r1:0)\n",
    "  if (p0.new) r3:2 = r1:0\n",
    " }}\n",
    " {{\n",
    "  r2 = convert_df2sf(r3:2)\n",
    "  r1:0 = #-1\n",
    "  jumpr r31\n",
    " }}\n",
    " .falign\n",
    ".Ltrue_zero:\n",
    " {{\n",
    "  r1:0 = r3:2\n",
    "  r3:2 = r1:0\n",
    " }}\n",
    ".Ltrue_inf:\n",
    " {{\n",
    "  r3 = extract(r3,#1,#31)\n",
    " }}\n",
    " {{\n",
    "  r1 ^= asl(r3,#31)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_sqrtdf2() {
        core::arch::asm!(
    " .set __qdsp_sqrtdf2, __hexagon_sqrtdf2; .type __qdsp_sqrtdf2,@function\n",
    " .set __qdsp_sqrt, __hexagon_sqrt; .type __qdsp_sqrt,@function\n",
    " .set __hexagon_fast_sqrtdf2, __hexagon_sqrtdf2; .type __hexagon_fast_sqrtdf2,@function\n",
    " .set __hexagon_fast_sqrt, __hexagon_sqrt; .type __hexagon_fast_sqrt,@function\n",
    " .set __hexagon_fast2_sqrtdf2, __hexagon_sqrtdf2; .type __hexagon_fast2_sqrtdf2,@function\n",
    " .set __hexagon_fast2_sqrt, __hexagon_sqrt; .type __hexagon_fast2_sqrt,@function\n",
    " .type sqrt,@function\n",
    " .p2align 5\n",
    " {{\n",
    "  r15:14 = extractu(r1:0,#23 +1,#52 -23)\n",
    "  r28 = extractu(r1,#11,#52 -32)\n",
    "  r5:4 = combine(##0x3f000004,#1)\n",
    " }}\n",
    " {{\n",
    "  p2 = dfclass(r1:0,#0x02)\n",
    "  p2 = cmp.gt(r1,#-1)\n",
    "  if (!p2.new) jump:nt .Lsqrt_abnormal\n",
    "  r9 = or(r5,r14)\n",
    " }}\n",
    "\n",
    ".Ldenormal_restart:\n",
    " {{\n",
    "  r11:10 = r1:0\n",
    "  r7,p0 = sfinvsqrta(r9)\n",
    "  r5 = and(r5,#-16)\n",
    "  r3:2 = #0\n",
    " }}\n",
    " {{\n",
    "  r3 += sfmpy(r7,r9):lib\n",
    "  r2 += sfmpy(r7,r5):lib\n",
    "  r6 = r5\n",
    "\n",
    "\n",
    "  r9 = and(r28,#1)\n",
    " }}\n",
    " {{\n",
    "  r6 -= sfmpy(r3,r2):lib\n",
    "  r11 = insert(r4,#11 +1,#52 -32)\n",
    "  p1 = cmp.gtu(r9,#0)\n",
    " }}\n",
    " {{\n",
    "  r3 += sfmpy(r3,r6):lib\n",
    "  r2 += sfmpy(r2,r6):lib\n",
    "  r6 = r5\n",
    "  r9 = mux(p1,#8,#9)\n",
    " }}\n",
    " {{\n",
    "  r6 -= sfmpy(r3,r2):lib\n",
    "  r11:10 = asl(r11:10,r9)\n",
    "  r9 = mux(p1,#3,#2)\n",
    " }}\n",
    " {{\n",
    "  r2 += sfmpy(r2,r6):lib\n",
    "\n",
    "  r15:14 = asl(r11:10,r9)\n",
    " }}\n",
    " {{\n",
    "  r2 = and(r2,##0x007fffff)\n",
    " }}\n",
    " {{\n",
    "  r2 = add(r2,##0x00800000 - 3)\n",
    "  r9 = mux(p1,#7,#8)\n",
    " }}\n",
    " {{\n",
    "  r8 = asl(r2,r9)\n",
    "  r9 = mux(p1,#15-(1+1),#15-(1+0))\n",
    " }}\n",
    " {{\n",
    "  r13:12 = mpyu(r8,r15)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = asl(r11:10,#15)\n",
    "  r15:14 = mpyu(r13,r13)\n",
    "  p1 = cmp.eq(r0,r0)\n",
    " }}\n",
    " {{\n",
    "  r1:0 -= asl(r15:14,#15)\n",
    "  r15:14 = mpyu(r13,r12)\n",
    "  p2 = cmp.eq(r0,r0)\n",
    " }}\n",
    " {{\n",
    "  r1:0 -= lsr(r15:14,#16)\n",
    "  p3 = cmp.eq(r0,r0)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = mpyu(r1,r8)\n",
    " }}\n",
    " {{\n",
    "  r13:12 += lsr(r1:0,r9)\n",
    "  r9 = add(r9,#16)\n",
    "  r1:0 = asl(r11:10,#31)\n",
    " }}\n",
    "\n",
    " {{\n",
    "  r15:14 = mpyu(r13,r13)\n",
    "  r1:0 -= mpyu(r13,r12)\n",
    " }}\n",
    " {{\n",
    "  r1:0 -= asl(r15:14,#31)\n",
    "  r15:14 = mpyu(r12,r12)\n",
    " }}\n",
    " {{\n",
    "  r1:0 -= lsr(r15:14,#33)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = mpyu(r1,r8)\n",
    " }}\n",
    " {{\n",
    "  r13:12 += lsr(r1:0,r9)\n",
    "  r9 = add(r9,#16)\n",
    "  r1:0 = asl(r11:10,#47)\n",
    " }}\n",
    "\n",
    " {{\n",
    "  r15:14 = mpyu(r13,r13)\n",
    " }}\n",
    " {{\n",
    "  r1:0 -= asl(r15:14,#47)\n",
    "  r15:14 = mpyu(r13,r12)\n",
    " }}\n",
    " {{\n",
    "  r1:0 -= asl(r15:14,#16)\n",
    "  r15:14 = mpyu(r12,r12)\n",
    " }}\n",
    " {{\n",
    "  r1:0 -= lsr(r15:14,#17)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = mpyu(r1,r8)\n",
    " }}\n",
    " {{\n",
    "  r13:12 += lsr(r1:0,r9)\n",
    " }}\n",
    " {{\n",
    "  r3:2 = mpyu(r13,r12)\n",
    "  r5:4 = mpyu(r12,r12)\n",
    "  r15:14 = #0\n",
    "  r1:0 = #0\n",
    " }}\n",
    " {{\n",
    "  r3:2 += lsr(r5:4,#33)\n",
    "  r5:4 += asl(r3:2,#33)\n",
    "  p1 = cmp.eq(r0,r0)\n",
    " }}\n",
    " {{\n",
    "  r7:6 = mpyu(r13,r13)\n",
    "  r1:0 = sub(r1:0,r5:4,p1):carry\n",
    "  r9:8 = #1\n",
    " }}\n",
    " {{\n",
    "  r7:6 += lsr(r3:2,#31)\n",
    "  r9:8 += asl(r13:12,#1)\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  r15:14 = sub(r11:10,r7:6,p1):carry\n",
    "  r5:4 = sub(r1:0,r9:8,p2):carry\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  r7:6 = #1\n",
    "  r11:10 = #0\n",
    " }}\n",
    " {{\n",
    "  r3:2 = sub(r15:14,r11:10,p2):carry\n",
    "  r7:6 = add(r13:12,r7:6)\n",
    "  r28 = add(r28,#-0x3ff)\n",
    " }}\n",
    " {{\n",
    "\n",
    "  if (p2) r13:12 = r7:6\n",
    "  if (p2) r1:0 = r5:4\n",
    "  if (p2) r15:14 = r3:2\n",
    " }}\n",
    " {{\n",
    "  r5:4 = sub(r1:0,r9:8,p3):carry\n",
    "  r7:6 = #1\n",
    "  r28 = asr(r28,#1)\n",
    " }}\n",
    " {{\n",
    "  r3:2 = sub(r15:14,r11:10,p3):carry\n",
    "  r7:6 = add(r13:12,r7:6)\n",
    " }}\n",
    " {{\n",
    "  if (p3) r13:12 = r7:6\n",
    "  if (p3) r1:0 = r5:4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  r2 = #1\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.eq(r1:0,r11:10)\n",
    "  if (!p0.new) r12 = or(r12,r2)\n",
    "  r3 = cl0(r13:12)\n",
    "  r28 = add(r28,#-63)\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  r1:0 = convert_ud2df(r13:12)\n",
    "  r28 = add(r28,r3)\n",
    " }}\n",
    " {{\n",
    "  r1 += asl(r28,#52 -32)\n",
    "  jumpr r31\n",
    " }}\n",
    ".Lsqrt_abnormal:\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#0x01)\n",
    "  if (p0.new) jumpr:t r31\n",
    " }}\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#0x10)\n",
    "  if (p0.new) jump:nt .Lsqrt_nan\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gt(r1,#-1)\n",
    "  if (!p0.new) jump:nt .Lsqrt_invalid_neg\n",
    "  if (!p0.new) r28 = ##0x7F800001\n",
    " }}\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#0x08)\n",
    "  if (p0.new) jumpr:nt r31\n",
    " }}\n",
    "\n",
    "\n",
    " {{\n",
    "  r1:0 = extractu(r1:0,#52,#0)\n",
    " }}\n",
    " {{\n",
    "  r28 = add(clb(r1:0),#-11)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = asl(r1:0,r28)\n",
    "  r28 = sub(#1,r28)\n",
    " }}\n",
    " {{\n",
    "  r1 = insert(r28,#1,#52 -32)\n",
    " }}\n",
    " {{\n",
    "  r3:2 = extractu(r1:0,#23 +1,#52 -23)\n",
    "  r5 = ##0x3f000004\n",
    " }}\n",
    " {{\n",
    "  r9 = or(r5,r2)\n",
    "  r5 = and(r5,#-16)\n",
    "  jump .Ldenormal_restart\n",
    " }}\n",
    ".Lsqrt_nan:\n",
    " {{\n",
    "  r28 = convert_df2sf(r1:0)\n",
    "  r1:0 = #-1\n",
    "  jumpr r31\n",
    " }}\n",
    ".Lsqrt_invalid_neg:\n",
    " {{\n",
    "  r1:0 = convert_sf2df(r28)\n",
    "  jumpr r31\n",
    " }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn fast2_dadd_asm() {
        core::arch::asm!(
    "        .falign\n",
    "      {{\n",
    "        R7:6 = VABSDIFFH(R1:0, R3:2)\n",
    "        R9 = #62\n",
    "        R4 = SXTH(R0)\n",
    "        R5 = SXTH(R2)\n",
    "      }} {{\n",
    "        R6 = SXTH(R6)\n",
    "        P0 = CMP.GT(R4, R5);\n",
    "        if ( P0.new) R8 = add(R4, #1)\n",
    "        if (!P0.new) R8 = add(R5, #1)\n",
    "      }} {{\n",
    "        if ( P0) R4 = #1\n",
    "        if (!P0) R5 = #1\n",
    "        R0.L = #0\n",
    "        R6 = MIN(R6, R9)\n",
    "      }} {{\n",
    "        if (!P0) R4 = add(R6, #1)\n",
    "        if ( P0) R5 = add(R6, #1)\n",
    "        R2.L = #0\n",
    "        R11:10 = #0\n",
    "      }} {{\n",
    "        R1:0 = ASR(R1:0, R4)\n",
    "        R3:2 = ASR(R3:2, R5)\n",
    "      }} {{\n",
    "        R1:0 = add(R1:0, R3:2)\n",
    "        R10.L = #0x8001\n",
    "      }} {{\n",
    "        R4 = clb(R1:0)\n",
    "        R9 = #58\n",
    "      }} {{\n",
    "        R4 = add(R4, #-1)\n",
    "        p0 = cmp.gt(R4, R9)\n",
    "      }} {{\n",
    "        R1:0 = ASL(R1:0, R4)\n",
    "        R8 = SUB(R8, R4)\n",
    "        if(p0) jump .Ldenorma0\n",
    "      }} {{\n",
    "        R0 = insert(R8, #16, #0)\n",
    "        jumpr r31\n",
    "      }}\n",
    ".Ldenorma0:\n",
    "      {{\n",
    "        R1:0 = R11:10\n",
    "        jumpr r31\n",
    "      }}\n",
    //"fast2_dsub_asm:\n",
    "        .falign\n",
    "      {{\n",
    "        R7:6 = VABSDIFFH(R1:0, R3:2)\n",
    "        R9 = #62\n",
    "        R4 = SXTH(R0)\n",
    "        R5 = SXTH(R2)\n",
    "      }} {{\n",
    "        R6 = SXTH(R6)\n",
    "        P0 = CMP.GT(R4, R5);\n",
    "        if ( P0.new) R8 = add(R4, #1)\n",
    "        if (!P0.new) R8 = add(R5, #1)\n",
    "      }} {{\n",
    "        if ( P0) R4 = #1\n",
    "        if (!P0) R5 = #1\n",
    "        R0.L = #0\n",
    "        R6 = MIN(R6, R9)\n",
    "      }} {{\n",
    "        if (!P0) R4 = add(R6, #1)\n",
    "        if ( P0) R5 = add(R6, #1)\n",
    "        R2.L = #0\n",
    "        R11:10 = #0\n",
    "      }} {{\n",
    "        R1:0 = ASR(R1:0, R4)\n",
    "        R3:2 = ASR(R3:2, R5)\n",
    "      }} {{\n",
    "        R1:0 = sub(R1:0, R3:2)\n",
    "        R10.L = #0x8001\n",
    "      }} {{\n",
    "        R4 = clb(R1:0)\n",
    "        R9 = #58\n",
    "      }} {{\n",
    "        R4 = add(R4, #-1)\n",
    "        p0 = cmp.gt(R4, R9)\n",
    "      }} {{\n",
    "        R1:0 = ASL(R1:0, R4)\n",
    "        R8 = SUB(R8, R4)\n",
    "        if(p0) jump .Ldenorm\n",
    "      }} {{\n",
    "        R0 = insert(R8, #16, #0)\n",
    "        jumpr r31\n",
    "      }}\n",
    ".Ldenorm:\n",
    "      {{\n",
    "        R1:0 = R11:10\n",
    "        jumpr r31\n",
    "      }}\n",
    //"fast2_dmpy_asm:\n",
    "        .falign\n",
    "      {{\n",
    "        R13= lsr(R2, #16)\n",
    "        R5 = sxth(R2)\n",
    "        R4 = sxth(R0)\n",
    "        R12= lsr(R0, #16)\n",
    "      }}\n",
    "      {{\n",
    "        R11:10 = mpy(R1, R3)\n",
    "        R7:6 = mpy(R1, R13)\n",
    "        R0.L = #0x0\n",
    "        R15:14 = #0\n",
    "      }}\n",
    "      {{\n",
    "        R11:10 = add(R11:10, R11:10)\n",
    "        R7:6 += mpy(R3, R12)\n",
    "        R2.L = #0x0\n",
    "        R15.H = #0x8000\n",
    "      }}\n",
    "      {{\n",
    "        R7:6 = asr(R7:6, #15)\n",
    "        R12.L = #0x8001\n",
    "        p1 = cmp.eq(R1:0, R3:2)\n",
    "      }}\n",
    "      {{\n",
    "        R7:6 = add(R7:6, R11:10)\n",
    "        R8 = add(R4, R5)\n",
    "        p2 = cmp.eq(R1:0, R15:14)\n",
    "      }}\n",
    "      {{\n",
    "        R9 = clb(R7:6)\n",
    "        R3:2 = abs(R7:6)\n",
    "        R11 = #58\n",
    "      }}\n",
    "      {{\n",
    "        p1 = and(p1, p2)\n",
    "        R8 = sub(R8, R9)\n",
    "        R9 = add(R9, #-1)\n",
    " p0 = cmp.gt(R9, R11)\n",
    "      }}\n",
    "      {{\n",
    "        R8 = add(R8, #1)\n",
    "        R1:0 = asl(R7:6, R9)\n",
    "        if(p1) jump .Lsat1\n",
    "      }}\n",
    "      {{\n",
    "        R0 = insert(R8,#16, #0)\n",
    "        if(!p0) jumpr r31\n",
    "      }}\n",
    "      {{\n",
    "        R0 = insert(R12,#16, #0)\n",
    "        jumpr r31\n",
    "      }}\n",
    ".Lsat1:\n",
    "      {{\n",
    "        R1:0 = #-1\n",
    "      }}\n",
    "      {{\n",
    "        R1:0 = lsr(R1:0, #1)\n",
    "      }}\n",
    "      {{\n",
    "        R0 = insert(R8,#16, #0)\n",
    "        jumpr r31\n",
    "      }}\n",
    //"fast2_qd2f_asm:\n",
    "      .falign\n",
    "     {{\n",
    "       R3 = abs(R1):sat\n",
    "       R4 = sxth(R0)\n",
    "       R5 = #0x40\n",
    "       R6.L = #0xffc0\n",
    "     }}\n",
    "     {{\n",
    "       R0 = extractu(R3, #8, #0)\n",
    "       p2 = cmp.gt(R4, #126)\n",
    "       p3 = cmp.ge(R4, #-126)\n",
    "       R6.H = #0x7fff\n",
    "     }}\n",
    "     {{\n",
    "       p1 = cmp.eq(R0,#0x40)\n",
    "       if(p1.new) R5 = #0\n",
    "       R4 = add(R4, #126)\n",
    "       if(!p3) jump .Lmin\n",
    "     }}\n",
    "     {{\n",
    "       p0 = bitsset(R3, R6)\n",
    "       R0.L = #0x0000\n",
    "       R2 = add(R3, R5)\n",
    "       R7 = lsr(R6, #8)\n",
    "     }}\n",
    "     {{\n",
    "       if(p0) R4 = add(R4, #1)\n",
    "       if(p0) R3 = #0\n",
    "       R2 = lsr(R2, #7)\n",
    "       R0.H = #0x8000\n",
    "     }}\n",
    "     {{\n",
    "       R0 = and(R0, R1)\n",
    "       R6 &= asl(R4, #23)\n",
    "       if(!p0) R3 = and(R2, R7)\n",
    "       if(p2) jump .Lmax\n",
    "     }}\n",
    "     {{\n",
    "       R0 += add(R6, R3)\n",
    "       jumpr r31\n",
    "     }}\n",
    ".Lmax:\n",
    "     {{\n",
    "       R0.L = #0xffff;\n",
    "     }}\n",
    "     {{\n",
    "       R0.H = #0x7f7f;\n",
    "       jumpr r31\n",
    "     }}\n",
    ".Lmin:\n",
    "     {{\n",
    "       R0 = #0x0\n",
    "       jumpr r31\n",
    "     }}\n",
    //"fast2_f2qd_asm:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        .falign\n",
    "  {{\n",
    "       R1 = asl(R0, #7)\n",
    "       p0 = tstbit(R0, #31)\n",
    "       R5:4 = #0\n",
    "       R3 = add(R0,R0)\n",
    "  }}\n",
    "  {{\n",
    "       R1 = setbit(R1, #30)\n",
    "       R0= extractu(R0,#8,#23)\n",
    "       R4.L = #0x8001\n",
    "       p1 = cmp.eq(R3, #0)\n",
    "  }}\n",
    "  {{\n",
    "       R1= extractu(R1, #31, #0)\n",
    "       R0= add(R0, #-126)\n",
    "       R2 = #0\n",
    "       if(p1) jump .Lminqd\n",
    "  }}\n",
    "  {{\n",
    "       R0 = zxth(R0)\n",
    "       if(p0) R1= sub(R2, R1)\n",
    "       jumpr r31\n",
    "  }}\n",
    ".Lminqd:\n",
    "  {{\n",
    "       R1:0 = R5:4\n",
    "       jumpr r31\n",
    "  }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn fast2_ldadd_asm() {
        core::arch::asm!(
    "        .falign\n",
    "      {{\n",
    "        R4 = memw(r29+#8)\n",
    "        R5 = memw(r29+#24)\n",
    "        r7 = r0\n",
    "      }}\n",
    "      {{\n",
    "        R6 = sub(R4, R5):sat\n",
    "        P0 = CMP.GT(R4, R5);\n",
    "        if ( P0.new) R8 = add(R4, #1)\n",
    "        if (!P0.new) R8 = add(R5, #1)\n",
    "      }} {{\n",
    "        R6 = abs(R6):sat\n",
    "        if ( P0) R4 = #1\n",
    "        if (!P0) R5 = #1\n",
    "        R9 = #62\n",
    "      }} {{\n",
    "        R6 = MIN(R6, R9)\n",
    "        R1:0 = memd(r29+#0)\n",
    "        R3:2 = memd(r29+#16)\n",
    "      }} {{\n",
    "        if (!P0) R4 = add(R6, #1)\n",
    "        if ( P0) R5 = add(R6, #1)\n",
    "      }} {{\n",
    "        R1:0 = ASR(R1:0, R4)\n",
    "        R3:2 = ASR(R3:2, R5)\n",
    "      }} {{\n",
    "        R1:0 = add(R1:0, R3:2)\n",
    "        R3:2 = #0\n",
    "      }} {{\n",
    "        R4 = clb(R1:0)\n",
    "        R9.L =#0x0001\n",
    "      }} {{\n",
    "        R8 -= add(R4, #-1)\n",
    "        R4 = add(R4, #-1)\n",
    "        p0 = cmp.gt(R4, #58)\n",
    "        R9.H =#0x8000\n",
    "      }} {{\n",
    "        if(!p0)memw(r7+#8) = R8\n",
    "        R1:0 = ASL(R1:0, R4)\n",
    "        if(p0) jump .Ldenorma1\n",
    "      }} {{\n",
    "        memd(r7+#0) = R1:0\n",
    "        jumpr r31\n",
    "      }}\n",
    ".Ldenorma1:\n",
    "        memd(r7+#0) = R3:2\n",
    "      {{\n",
    "        memw(r7+#8) = R9\n",
    "        jumpr r31\n",
    "      }}\n",
        options(noreturn)
        );
    }

    #[naked]
    pub unsafe extern "C" fn fast2_ldsub_asm() {
        core::arch::asm!(
    "        .falign\n",
    "      {{\n",
    "        R4 = memw(r29+#8)\n",
    "        R5 = memw(r29+#24)\n",
    "        r7 = r0\n",
    "      }}\n",
    "      {{\n",
    "        R6 = sub(R4, R5):sat\n",
    "        P0 = CMP.GT(R4, R5);\n",
    "        if ( P0.new) R8 = add(R4, #1)\n",
    "        if (!P0.new) R8 = add(R5, #1)\n",
    "      }} {{\n",
    "        R6 = abs(R6):sat\n",
    "        if ( P0) R4 = #1\n",
    "        if (!P0) R5 = #1\n",
    "        R9 = #62\n",
    "      }} {{\n",
    "        R6 = min(R6, R9)\n",
    "        R1:0 = memd(r29+#0)\n",
    "        R3:2 = memd(r29+#16)\n",
    "      }} {{\n",
    "        if (!P0) R4 = add(R6, #1)\n",
    "        if ( P0) R5 = add(R6, #1)\n",
    "      }} {{\n",
    "        R1:0 = ASR(R1:0, R4)\n",
    "        R3:2 = ASR(R3:2, R5)\n",
    "      }} {{\n",
    "        R1:0 = sub(R1:0, R3:2)\n",
    "        R3:2 = #0\n",
    "      }} {{\n",
    "        R4 = clb(R1:0)\n",
    "        R9.L =#0x0001\n",
    "      }} {{\n",
    "        R8 -= add(R4, #-1)\n",
    "        R4 = add(R4, #-1)\n",
    "        p0 = cmp.gt(R4, #58)\n",
    "        R9.H =#0x8000\n",
    "      }} {{\n",
    "        if(!p0)memw(r7+#8) = R8\n",
    "        R1:0 = asl(R1:0, R4)\n",
    "        if(p0) jump .Ldenorma_s\n",
    "      }} {{\n",
    "        memd(r7+#0) = R1:0\n",
    "        jumpr r31\n",
    "      }}\n",
    ".Ldenorma_s:\n",
    "        memd(r7+#0) = R3:2\n",
    "      {{\n",
    "        memw(r7+#8) = R9\n",
    "        jumpr r31\n",
    "      }}\n",
        options(noreturn)
        );
    }

    #[naked]
    pub unsafe extern "C" fn fast2_ldmpy_asm() {
        core::arch::asm!(
    "        .falign\n",
    "      {{\n",
    "        R15:14 = memd(r29+#0)\n",
    "        R3:2 = memd(r29+#16)\n",
    "        R13:12 = #0\n",
    "      }}\n",
    "      {{\n",
    "        R8= extractu(R2, #31, #1)\n",
    "        R9= extractu(R14, #31, #1)\n",
    "        R13.H = #0x8000\n",
    "      }}\n",
    "      {{\n",
    "        R11:10 = mpy(R15, R3)\n",
    "        R7:6 = mpy(R15, R8)\n",
    "        R4 = memw(r29+#8)\n",
    "        R5 = memw(r29+#24)\n",
    "      }}\n",
    "      {{\n",
    "        R11:10 = add(R11:10, R11:10)\n",
    "        R7:6 += mpy(R3, R9)\n",
    "      }}\n",
    "      {{\n",
    "        R7:6 = asr(R7:6, #30)\n",
    "        R8.L = #0x0001\n",
    "        p1 = cmp.eq(R15:14, R3:2)\n",
    "      }}\n",
    "      {{\n",
    "        R7:6 = add(R7:6, R11:10)\n",
    "        R4= add(R4, R5)\n",
    "        p2 = cmp.eq(R3:2, R13:12)\n",
    "      }}\n",
    "      {{\n",
    "        R9 = clb(R7:6)\n",
    "        R8.H = #0x8000\n",
    "        p1 = and(p1, p2)\n",
    "      }}\n",
    "      {{\n",
    "        R4-= add(R9, #-1)\n",
    "        R9 = add(R9, #-1)\n",
    "        if(p1) jump .Lsat0\n",
    "      }}\n",
    "      {{\n",
    "        R7:6 = asl(R7:6, R9)\n",
    "        memw(R0+#8) = R4\n",
    " p0 = cmp.gt(R9, #58)\n",
    "        if(p0.new) jump:NT .Ldenorm0\n",
    "      }}\n",
    "      {{\n",
    "        memd(R0+#0) = R7:6\n",
    "        jumpr r31\n",
    "      }}\n",
    ".Lsat0:\n",
    "      {{\n",
    "        R13:12 = #0\n",
    "        R4+= add(R9, #1)\n",
    "      }}\n",
    "      {{\n",
    "        R13.H = #0x4000\n",
    "        memw(R0+#8) = R4\n",
    "      }}\n",
    "      {{\n",
    "        memd(R0+#0) = R13:12\n",
    "        jumpr r31\n",
    "      }}\n",
    ".Ldenorm0:\n",
    "      {{\n",
    "        memw(R0+#8) = R8\n",
    "        R15:14 = #0\n",
    "      }}\n",
    "      {{\n",
    "        memd(R0+#0) = R15:14\n",
    "        jumpr r31\n",
    "      }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn dadd_asm() {
        core::arch::asm!(
    "        .falign\n",
    "      {{\n",
    "        R7:6 = VABSDIFFH(R1:0, R3:2)\n",
    "        R9 = #62\n",
    "        R4 = SXTH(R0)\n",
    "        R5 = SXTH(R2)\n",
    "      }} {{\n",
    "        R6 = SXTH(R6)\n",
    "        P0 = CMP.GT(R4, R5);\n",
    "        if ( P0.new) R8 = add(R4, #1)\n",
    "        if (!P0.new) R8 = add(R5, #1)\n",
    "      }} {{\n",
    "        if ( P0) R4 = #1\n",
    "        if (!P0) R5 = #1\n",
    "        R0.L = #0\n",
    "        R6 = MIN(R6, R9)\n",
    "      }} {{\n",
    "        if (!P0) R4 = add(R6, #1)\n",
    "        if ( P0) R5 = add(R6, #1)\n",
    "        R2.L = #0\n",
    "        R7:6 = #0\n",
    "      }} {{\n",
    "        R1:0 = ASR(R1:0, R4)\n",
    "        R3:2 = ASR(R3:2, R5)\n",
    "        R11:10 = #0\n",
    "      }} {{\n",
    "        R1:0 = add(R1:0, R3:2)\n",
    "        R3:2 = #-1\n",
    "        R11.H = #0x8000\n",
    "      }} {{\n",
    "        R4 = NORMAMT(R1)\n",
    "        R5 = NORMAMT(R0)\n",
    "        p0 = cmp.eq(R1, R6)\n",
    "        p1 = cmp.eq(R1, R2)\n",
    "      }} {{\n",
    "        p0 = OR(p0, p1)\n",
    "        if(p0.new) R4 = add(R5, #31)\n",
    "        R9.H = #0\n",
    "      }} {{\n",
    "        R1:0 = ASL(R1:0, R4)\n",
    "        R8 = SUB(R8, R4)\n",
    "        R9.L = #0x8001\n",
    "      }} {{\n",
    "        p0 = cmp.eq(R1:0, R7:6)\n",
    "        p1 = cmp.eq(R1:0, R3:2)\n",
    "        R0.L = #0\n",
    "        R8 = ZXTH(R8)\n",
    "      }} {{\n",
    "        p2 = cmp.eq(R1:0, R11:10)\n",
    "        if(p2.new) R8 = add(R8, #1)\n",
    "      }}\n",
    "      {{\n",
    "        p0 = OR(p0, p1)\n",
    "        if( p0.new) R0 = OR(R0,R9)\n",
    "        if(!p0.new) R0 = OR(R0,R8)\n",
    "        jumpr r31\n",
    "      }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn dsub_asm() {
        core::arch::asm!(
    "        .falign\n",
    "      {{\n",
    "        R7:6 = VABSDIFFH(R1:0, R3:2)\n",
    "        R9 = #62\n",
    "        R4 = SXTH(R0)\n",
    "        R5 = SXTH(R2)\n",
    "      }} {{\n",
    "        R6 = SXTH(R6)\n",
    "        P0 = CMP.GT(R4, R5);\n",
    "        if ( P0.new) R8 = add(R4, #1)\n",
    "        if (!P0.new) R8 = add(R5, #1)\n",
    "      }} {{\n",
    "        if ( P0) R4 = #1\n",
    "        if (!P0) R5 = #1\n",
    "        R0.L = #0\n",
    "        R6 = MIN(R6, R9)\n",
    "      }} {{\n",
    "        if (!P0) R4 = add(R6, #1)\n",
    "        if ( P0) R5 = add(R6, #1)\n",
    "        R2.L = #0\n",
    "        R7:6 = #0\n",
    "      }} {{\n",
    "        R1:0 = ASR(R1:0, R4)\n",
    "        R3:2 = ASR(R3:2, R5)\n",
    "        R11:10 = #0\n",
    "      }} {{\n",
    "        R1:0 = sub(R1:0, R3:2)\n",
    "        R3:2 = #-1\n",
    "        R11.H = #0x8000\n",
    "      }} {{\n",
    "        R4 = NORMAMT(R1)\n",
    "        R5 = NORMAMT(R0)\n",
    "        p0 = cmp.eq(R1, R6)\n",
    "        p1 = cmp.eq(R1, R2)\n",
    "      }} {{\n",
    "        p0 = OR(p0, p1)\n",
    "        if(p0.new) R4 = add(R5, #31)\n",
    "        R9.H = #0\n",
    "      }} {{\n",
    "        R1:0 = ASL(R1:0, R4)\n",
    "        R8 = SUB(R8, R4)\n",
    "        R9.L = #0x8001\n",
    "      }} {{\n",
    "        p0 = cmp.eq(R1:0, R7:6)\n",
    "        p1 = cmp.eq(R1:0, R3:2)\n",
    "        R0.L = #0\n",
    "        R8 = ZXTH(R8)\n",
    "      }} {{\n",
    "        p2 = cmp.eq(R1:0, R11:10)\n",
    "        if(p2.new) R8 = add(R8, #1)\n",
    "      }}\n",
    "      {{\n",
    "        p0 = OR(p0, p1)\n",
    "        if( p0.new) R0 = OR(R0,R9)\n",
    "        if(!p0.new) R0 = OR(R0,R8)\n",
    "        jumpr r31\n",
    "      }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn dmpy_asm() {
        core::arch::asm!(
    "        .falign\n",
    "      {{\n",
    "        R2 = lsr(R2, #16)\n",
    "        R0 = lsr(R0, #16)\n",
    "        R4 = sxth(R0)\n",
    "        R5 = sxth(R2)\n",
    "      }}\n",
    "      {{\n",
    "        R11:10 = mpy(R1, R3)\n",
    "        R7:6 = mpy(R1, R2)\n",
    "      }}\n",
    "      {{\n",
    "        R11:10 = add(R11:10, R11:10)\n",
    "        R7:6 += mpy(R3, R0)\n",
    "      }}\n",
    "      {{\n",
    "        R11:10 += asr(R7:6, #15)\n",
    "        R8 = add(R4, R5)\n",
    "        R7:6 = #0\n",
    "        R3:2 = #-1\n",
    "      }}\n",
    "      {{\n",
    "        R4 = normamt(R11)\n",
    "        R5 = normamt(R10)\n",
    "        p0 = cmp.eq(R11, R6)\n",
    "        p1 = cmp.eq(R11, R2)\n",
    "      }}\n",
    "      {{\n",
    "        p0 = or(p0, p1)\n",
    "        if(p0.new) R4 = add(R5, #31)\n",
    "        R9.H = #0\n",
    "      }}\n",
    "      {{\n",
    "        R1:0 = asl(R11:10, R4)\n",
    "        R8 = sub(R8, R4)\n",
    "        R9.L = #0x8001\n",
    "      }}\n",
    "      {{\n",
    "        p0 = cmp.eq(R1:0, R7:6)\n",
    "        p1 = cmp.eq(R1:0, R3:2)\n",
    "        R0.L = #0\n",
    "        R8 = zxth(R8)\n",
    "      }}\n",
    "      {{\n",
    "        p0 = or(p0, p1)\n",
    "        if( p0.new) R0 = or(R0,R9)\n",
    "        if(!p0.new) R0 = or(R0,R8)\n",
    "        jumpr r31\n",
    "      }}\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn hexagon_memcpy_forward_vp4cp4n2() {
        core::arch::asm!(
    "  .balign 32\n",
    "  {{\n",
    "    r3 = sub(##4096, r1)\n",
    "    r5 = lsr(r2, #3)\n",
    "  }}\n",
    "  {{\n",
    "\n",
    "\n",
    "    r3 = extractu(r3, #10, #2)\n",
    "    r4 = extractu(r3, #7, #5)\n",
    "  }}\n",
    "  {{\n",
    "    r3 = minu(r2, r3)\n",
    "    r4 = minu(r5, r4)\n",
    "  }}\n",
    "  {{\n",
    "    r4 = or(r4, ##2105344)\n",
    "    p0 = cmp.eq(r3, #0)\n",
    "    if (p0.new) jump:nt .Lskipprolog\n",
    "  }}\n",
    "    l2fetch(r1, r4)\n",
    "  {{\n",
    "    loop0(.Lprolog, r3)\n",
    "    r2 = sub(r2, r3)\n",
    "  }}\n",
    "  .falign\n",
    ".Lprolog:\n",
    "  {{\n",
    "    r4 = memw(r1++#4)\n",
    "    memw(r0++#4) = r4.new\n",
    "  }} :endloop0\n",
    ".Lskipprolog:\n",
    "  {{\n",
    "\n",
    "    r3 = lsr(r2, #10)\n",
    "    if (cmp.eq(r3.new, #0)) jump:nt .Lskipmain\n",
    "  }}\n",
    "  {{\n",
    "    loop1(.Lout, r3)\n",
    "    r2 = extractu(r2, #10, #0)\n",
    "    r3 = ##2105472\n",
    "  }}\n",
    "\n",
    "  .falign\n",
    ".Lout:\n",
    "\n",
    "    l2fetch(r1, r3)\n",
    "    loop0(.Lpage, #512)\n",
    "  .falign\n",
    ".Lpage:\n",
    "    r5:4 = memd(r1++#8)\n",
    "  {{\n",
    "    memw(r0++#8) = r4\n",
    "    memw(r0+#4) = r5\n",
    "  }} :endloop0:endloop1\n",
    ".Lskipmain:\n",
    "  {{\n",
    "    r3 = ##2105344\n",
    "    r4 = lsr(r2, #3)\n",
    "    p0 = cmp.eq(r2, #0)\n",
    "    if (p0.new) jumpr:nt r31\n",
    "  }}\n",
    "  {{\n",
    "    r3 = or(r3, r4)\n",
    "    loop0(.Lepilog, r2)\n",
    "  }}\n",
    "    l2fetch(r1, r3)\n",
    "  .falign\n",
    ".Lepilog:\n",
    "  {{\n",
    "    r4 = memw(r1++#4)\n",
    "    memw(r0++#4) = r4.new\n",
    "  }} :endloop0\n",
    "\n",
    "    jumpr r31\n",
    "\n",
        options(noreturn)
        );
    }

#[naked]
    pub unsafe extern "C" fn __hexagon_fmadf4() {
        core::arch::asm!(
    " .set __qdsp_fmadf5, __hexagon_fmadf5\n",
    " .p2align 5\n",
    ".Lfma_begin:\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#2)\n",
    "  p0 = dfclass(r3:2,#2)\n",
    "  r13:12 = #0\n",
    "  r15:14 = #0\n",
    " }}\n",
    " {{\n",
    "  r13:12 = insert(r1:0,#52,#11 -3)\n",
    "  r15:14 = insert(r3:2,#52,#11 -3)\n",
    "  r7 = ##0x10000000\n",
    "  allocframe(#32)\n",
    " }}\n",
    " {{\n",
    "  r9:8 = mpyu(r12,r14)\n",
    "  if (!p0) jump .Lfma_abnormal_ab\n",
    "  r13 = or(r13,r7)\n",
    "  r15 = or(r15,r7)\n",
    " }}\n",
    " {{\n",
    "  p0 = dfclass(r5:4,#2)\n",
    "  if (!p0.new) jump:nt .Lfma_abnormal_c\n",
    "  r11:10 = combine(r7,#0)\n",
    "  r7:6 = combine(#0,r9)\n",
    " }}\n",
    ".Lfma_abnormal_c_restart:\n",
    " {{\n",
    "  r7:6 += mpyu(r14,r13)\n",
    "  r11:10 = insert(r5:4,#52,#11 -3)\n",
    "  memd(r29+#0) = r17:16\n",
    "  memd(r29+#8) = r19:18\n",
    " }}\n",
    " {{\n",
    "  r7:6 += mpyu(r12,r15)\n",
    "  r19:18 = neg(r11:10)\n",
    "  p0 = cmp.gt(r5,#-1)\n",
    "  r28 = xor(r1,r3)\n",
    " }}\n",
    " {{\n",
    "  r18 = extractu(r1,#11,#20)\n",
    "  r19 = extractu(r3,#11,#20)\n",
    "  r17:16 = combine(#0,r7)\n",
    "  if (!p0) r11:10 = r19:18\n",
    " }}\n",
    " {{\n",
    "  r17:16 += mpyu(r13,r15)\n",
    "  r9:8 = combine(r6,r8)\n",
    "  r18 = add(r18,r19)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  r19 = extractu(r5,#11,#20)\n",
    " }}\n",
    " {{\n",
    "  r18 = add(r18,#-1023 +(4))\n",
    "  p3 = !cmp.gt(r28,#-1)\n",
    "  r7:6 = #0\n",
    "  r15:14 = #0\n",
    " }}\n",
    " {{\n",
    "  r7:6 = sub(r7:6,r9:8,p3):carry\n",
    "  p0 = !cmp.gt(r28,#-1)\n",
    "  p1 = cmp.gt(r19,r18)\n",
    "  if (p1.new) r19:18 = combine(r18,r19)\n",
    " }}\n",
    " {{\n",
    "  r15:14 = sub(r15:14,r17:16,p3):carry\n",
    "  if (p0) r9:8 = r7:6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  r7:6 = #0\n",
    "  r19 = sub(r18,r19)\n",
    " }}\n",
    " {{\n",
    "  if (p0) r17:16 = r15:14\n",
    "  p0 = cmp.gt(r19,#63)\n",
    "  if (p1) r9:8 = r7:6\n",
    "  if (p1) r7:6 = r9:8\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  if (p1) r17:16 = r11:10\n",
    "  if (p1) r11:10 = r17:16\n",
    "  if (p0) r19 = add(r19,#-64)\n",
    "  r28 = #63\n",
    " }}\n",
    " {{\n",
    "\n",
    "  if (p0) r7:6 = r11:10\n",
    "  r28 = asr(r11,#31)\n",
    "  r13 = min(r19,r28)\n",
    "  r12 = #0\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  if (p0) r11:10 = combine(r28,r28)\n",
    "  r5:4 = extract(r7:6,r13:12)\n",
    "  r7:6 = lsr(r7:6,r13)\n",
    "  r12 = sub(#64,r13)\n",
    " }}\n",
    " {{\n",
    "  r15:14 = #0\n",
    "  r28 = #-2\n",
    "  r7:6 |= lsl(r11:10,r12)\n",
    "  r11:10 = asr(r11:10,r13)\n",
    " }}\n",
    " {{\n",
    "  p3 = cmp.gtu(r5:4,r15:14)\n",
    "  if (p3.new) r6 = and(r6,r28)\n",
    "\n",
    "\n",
    "\n",
    "  r15:14 = #1\n",
    "  r5:4 = #0\n",
    " }}\n",
    " {{\n",
    "  r9:8 = add(r7:6,r9:8,p3):carry\n",
    " }}\n",
    " {{\n",
    "  r17:16 = add(r11:10,r17:16,p3):carry\n",
    "  r28 = #62\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  r12 = add(clb(r17:16),#-2)\n",
    "  if (!cmp.eq(r12.new,r28)) jump:t 1f\n",
    " }}\n",
    "\n",
    " {{\n",
    "  r11:10 = extractu(r9:8,#62,#2)\n",
    "  r9:8 = asl(r9:8,#62)\n",
    "  r18 = add(r18,#-62)\n",
    " }}\n",
    " {{\n",
    "  r17:16 = insert(r11:10,#62,#0)\n",
    " }}\n",
    " {{\n",
    "  r12 = add(clb(r17:16),#-2)\n",
    " }}\n",
    " .falign\n",
    "1:\n",
    " {{\n",
    "  r11:10 = asl(r17:16,r12)\n",
    "  r5:4 |= asl(r9:8,r12)\n",
    "  r13 = sub(#64,r12)\n",
    "  r18 = sub(r18,r12)\n",
    " }}\n",
    " {{\n",
    "  r11:10 |= lsr(r9:8,r13)\n",
    "  p2 = cmp.gtu(r15:14,r5:4)\n",
    "  r28 = #1023 +1023 -2\n",
    " }}\n",
    " {{\n",
    "  if (!p2) r10 = or(r10,r14)\n",
    "\n",
    "  p0 = !cmp.gt(r18,r28)\n",
    "  p0 = cmp.gt(r18,#1)\n",
    "  if (!p0.new) jump:nt .Lfma_ovf_unf\n",
    " }}\n",
    " {{\n",
    "\n",
    "  p0 = cmp.gtu(r15:14,r11:10)\n",
    "  r1:0 = convert_d2df(r11:10)\n",
    "  r18 = add(r18,#-1023 -60)\n",
    "  r17:16 = memd(r29+#0)\n",
    " }}\n",
    " {{\n",
    "  r1 += asl(r18,#20)\n",
    "  r19:18 = memd(r29+#8)\n",
    "  if (!p0) dealloc_return\n",
    " }}\n",
    ".Ladd_yields_zero:\n",
    "\n",
    " {{\n",
    "  r28 = USR\n",
    "  r1:0 = #0\n",
    " }}\n",
    " {{\n",
    "  r28 = extractu(r28,#2,#22)\n",
    "  r17:16 = memd(r29+#0)\n",
    "  r19:18 = memd(r29+#8)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.eq(r28,#2)\n",
    "  if (p0.new) r1 = ##0x80000000\n",
    "  dealloc_return\n",
    " }}\n",
    ".Lfma_ovf_unf:\n",
    " {{\n",
    "  p0 = cmp.gtu(r15:14,r11:10)\n",
    "  if (p0.new) jump:nt .Ladd_yields_zero\n",
    " }}\n",
    " {{\n",
    "  r1:0 = convert_d2df(r11:10)\n",
    "  r18 = add(r18,#-1023 -60)\n",
    "  r28 = r18\n",
    " }}\n",
    "\n",
    "\n",
    " {{\n",
    "  r1 += asl(r18,#20)\n",
    "  r7 = extractu(r1,#11,#20)\n",
    " }}\n",
    " {{\n",
    "  r6 = add(r18,r7)\n",
    "  r17:16 = memd(r29+#0)\n",
    "  r19:18 = memd(r29+#8)\n",
    "  r9:8 = abs(r11:10)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gt(r6,##1023 +1023)\n",
    "  if (p0.new) jump:nt .Lfma_ovf\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gt(r6,#0)\n",
    "  if (p0.new) jump:nt .Lpossible_unf1\n",
    " }}\n",
    " {{\n",
    "\n",
    "\n",
    "\n",
    "  r7 = add(clb(r9:8),#-2)\n",
    "  r6 = sub(#1+5,r28)\n",
    "  p3 = cmp.gt(r11,#-1)\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  r6 = add(r6,r7)\n",
    "  r9:8 = asl(r9:8,r7)\n",
    "  r1 = USR\n",
    "  r28 = #63\n",
    " }}\n",
    " {{\n",
    "  r7 = min(r6,r28)\n",
    "  r6 = #0\n",
    "  r0 = #0x0030\n",
    " }}\n",
    " {{\n",
    "  r3:2 = extractu(r9:8,r7:6)\n",
    "  r9:8 = asr(r9:8,r7)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.gtu(r15:14,r3:2)\n",
    "  if (!p0.new) r8 = or(r8,r14)\n",
    "  r9 = setbit(r9,#20 +3)\n",
    " }}\n",
    " {{\n",
    "  r11:10 = neg(r9:8)\n",
    "  p1 = bitsclr(r8,#(1<<3)-1)\n",
    "  if (!p1.new) r1 = or(r1,r0)\n",
    "  r3:2 = #0\n",
    " }}\n",
    " {{\n",
    "  if (p3) r11:10 = r9:8\n",
    "  USR = r1\n",
    "  r28 = #-1023 -(52 +3)\n",
    " }}\n",
    " {{\n",
    "  r1:0 = convert_d2df(r11:10)\n",
    " }}\n",
    " {{\n",
    "  r1 += asl(r28,#20)\n",
    "  dealloc_return\n",
    " }}\n",
    ".Lpossible_unf1:\n",
    " {{\n",
    "  r28 = ##0x7fefffff\n",
    "  r9:8 = abs(r11:10)\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.eq(r0,#0)\n",
    "  p0 = bitsclr(r1,r28)\n",
    "  if (!p0.new) dealloc_return:t\n",
    "  r28 = #0x7fff\n",
    " }}\n",
    " {{\n",
    "  p0 = bitsset(r9,r28)\n",
    "  r3 = USR\n",
    "  r2 = #0x0030\n",
    " }}\n",
    " {{\n",
    "  if (p0) r3 = or(r3,r2)\n",
    " }}\n",
    " {{\n",
    "  USR = r3\n",
    " }}\n",
    " {{\n",
    "  p0 = dfcmp.eq(r1:0,r1:0)\n",
    "  dealloc_return\n",
    " }}\n",
    ".Lfma_ovf:\n",
    " {{\n",
    "  r28 = USR\n",
    "  r11:10 = combine(##0x7fefffff,#-1)\n",
    "  r1:0 = r11:10\n",
    " }}\n",
    " {{\n",
    "  r9:8 = combine(##0x7ff00000,#0)\n",
    "  r3 = extractu(r28,#2,#22)\n",
    "  r28 = or(r28,#0x28)\n",
    " }}\n",
    " {{\n",
    "  USR = r28\n",
    "  r3 ^= lsr(r1,#31)\n",
    "  r2 = r3\n",
    " }}\n",
    " {{\n",
    "  p0 = !cmp.eq(r2,#1)\n",
    "  p0 = !cmp.eq(r3,#2)\n",
    " }}\n",
    " {{\n",
    "  p0 = dfcmp.eq(r9:8,r9:8)\n",
    "  if (p0.new) r11:10 = r9:8\n",
    " }}\n",
    " {{\n",
    "  r1:0 = insert(r11:10,#63,#0)\n",
    "  dealloc_return\n",
    " }}\n",
    ".Lfma_abnormal_ab:\n",
    " {{\n",
    "  r9:8 = extractu(r1:0,#63,#0)\n",
    "  r11:10 = extractu(r3:2,#63,#0)\n",
    "  deallocframe\n",
    " }}\n",
    " {{\n",
    "  p3 = cmp.gtu(r9:8,r11:10)\n",
    "  if (!p3.new) r1:0 = r3:2\n",
    "  if (!p3.new) r3:2 = r1:0\n",
    " }}\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#0x0f)\n",
    "  if (!p0.new) jump:nt .Lnan\n",
    "  if (!p3) r9:8 = r11:10\n",
    "  if (!p3) r11:10 = r9:8\n",
    " }}\n",
    " {{\n",
    "  p1 = dfclass(r1:0,#0x08)\n",
    "  p1 = dfclass(r3:2,#0x0e)\n",
    " }}\n",
    " {{\n",
    "  p0 = dfclass(r1:0,#0x08)\n",
    "  p0 = dfclass(r3:2,#0x01)\n",
    " }}\n",
    " {{\n",
    "  if (p1) jump .Lab_inf\n",
    "  p2 = dfclass(r3:2,#0x01)\n",
    " }}\n",
    " {{\n",
    "  if (p0) jump .Linvalid\n",
    "  if (p2) jump .Lab_true_zero\n",
    "  r28 = ##0x7c000000\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " {{\n",
    "  p0 = bitsclr(r1,r28)\n",
    "  if (p0.new) jump:nt .Lfma_ab_tiny\n",
    " }}\n",
    " {{\n",
    "  r28 = add(clb(r11:10),#-11)\n",
    " }}\n",
    " {{\n",
    "  r11:10 = asl(r11:10,r28)\n",
    " }}\n",
    " {{\n",
    "  r3:2 = insert(r11:10,#63,#0)\n",
    "  r1 -= asl(r28,#20)\n",
    " }}\n",
    " jump .Lfma_begin\n",
    "\n",
    ".Lfma_ab_tiny:\n",
    " r9:8 = combine(##0x00100000,#0)\n",
    " {{\n",
    "  r1:0 = insert(r9:8,#63,#0)\n",
    "  r3:2 = insert(r9:8,#63,#0)\n",
    " }}\n",
    " jump .Lfma_begin\n",
    "\n",
    ".Lab_inf:\n",
    " {{\n",
    "  r3:2 = lsr(r3:2,#63)\n",
    "  p0 = dfclass(r5:4,#0x10)\n",
    " }}\n",
    " {{\n",
    "  r1:0 ^= asl(r3:2,#63)\n",
    "  if (p0) jump .Lnan\n",
    " }}\n",
    " {{\n",
    "  p1 = dfclass(r5:4,#0x08)\n",
    "  if (p1.new) jump:nt .Lfma_inf_plus_inf\n",
    " }}\n",
    "\n",
    " {{\n",
    "  jumpr r31\n",
    " }}\n",
    " .falign\n",
    ".Lfma_inf_plus_inf:\n",
    " {{\n",
    "  p0 = dfcmp.eq(r1:0,r5:4)\n",
    "  if (!p0.new) jump:nt .Linvalid\n",
    " }}\n",
    " {{\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    ".Lnan:\n",
    " {{\n",
    "  p0 = dfclass(r3:2,#0x10)\n",
    "  p1 = dfclass(r5:4,#0x10)\n",
    "  if (!p0.new) r3:2 = r1:0\n",
    "  if (!p1.new) r5:4 = r1:0\n",
    " }}\n",
    " {{\n",
    "  r3 = convert_df2sf(r3:2)\n",
    "  r2 = convert_df2sf(r5:4)\n",
    " }}\n",
    " {{\n",
    "  r3 = convert_df2sf(r1:0)\n",
    "  r1:0 = #-1\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    ".Linvalid:\n",
    " {{\n",
    "  r28 = ##0x7f800001\n",
    " }}\n",
    " {{\n",
    "  r1:0 = convert_sf2df(r28)\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    ".Lab_true_zero:\n",
    "\n",
    " {{\n",
    "  p0 = dfclass(r5:4,#0x10)\n",
    "  if (p0.new) jump:nt .Lnan\n",
    "  if (p0.new) r1:0 = r5:4\n",
    " }}\n",
    " {{\n",
    "  p0 = dfcmp.eq(r3:2,r5:4)\n",
    "  r1 = lsr(r1,#31)\n",
    " }}\n",
    " {{\n",
    "  r3 ^= asl(r1,#31)\n",
    "  if (!p0) r1:0 = r5:4\n",
    "  if (!p0) jumpr r31\n",
    " }}\n",
    "\n",
    ".Lzero_plus_zero1:\n",
    " {{\n",
    "  p0 = cmp.eq(r3:2,r5:4)\n",
    "  if (p0.new) jumpr:t r31\n",
    "  r1:0 = r3:2\n",
    " }}\n",
    " {{\n",
    "  r28 = USR\n",
    " }}\n",
    " {{\n",
    "  r28 = extractu(r28,#2,#22)\n",
    "  r1:0 = #0\n",
    " }}\n",
    " {{\n",
    "  p0 = cmp.eq(r28,#2)\n",
    "  if (p0.new) r1 = ##0x80000000\n",
    "  jumpr r31\n",
    " }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " .falign\n",
    ".Lfma_abnormal_c:\n",
    "\n",
    "\n",
    " {{\n",
    "  p0 = dfclass(r5:4,#0x10)\n",
    "  if (p0.new) jump:nt .Lnan\n",
    "  if (p0.new) r1:0 = r5:4\n",
    "  deallocframe\n",
    " }}\n",
    " {{\n",
    "  p0 = dfclass(r5:4,#0x08)\n",
    "  if (p0.new) r1:0 = r5:4\n",
    "  if (p0.new) jumpr:nt r31\n",
    " }}\n",
    "\n",
    "\n",
    " {{\n",
    "  p0 = dfclass(r5:4,#0x01)\n",
    "  if (p0.new) jump:nt __hexagon_muldf3\n",
    "  r28 = #1\n",
    " }}\n",
    "\n",
    "\n",
    " {{\n",
    "  allocframe(#32)\n",
    "  r11:10 = #0\n",
    "  r5 = insert(r28,#11,#20)\n",
    "  jump .Lfma_abnormal_c_restart\n",
    " }}\n",
        options(noreturn)
        );
    }

}
